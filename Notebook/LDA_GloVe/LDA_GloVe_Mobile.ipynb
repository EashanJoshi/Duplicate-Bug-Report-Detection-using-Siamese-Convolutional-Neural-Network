{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcEh6XNB_R72",
        "outputId": "a3ffd600-871d-40d7-cc9e-fee3c6af0320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.8/dist-packages (3.4.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.18)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from glove-python-binary) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from glove-python-binary) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "# For Installation (Required)\n",
        "!pip install pyLDAvis\n",
        "!pip install glove-python-binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "import time\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "from gensim import corpora,models\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.models import Word2Vec,FastText\n",
        "from gensim.test.utils import get_tmpfile\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from glove import Glove\n",
        "from glove import Corpus\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1syBdp1UQFCa",
        "outputId": "04486151-c609-4900-e849-786b43445cb4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ZzbGRFIW7o",
        "outputId": "fa13a969-078a-4b03-8ed7-2f7769626af7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Whole Dataset\n",
        "mobile_data=pd.read_csv('/content/drive/Shareddrives/DSCI-644-Team-5/PrimaryDataset/mobile_preproccessed_whole_dataset.csv')\n",
        "\n",
        "#Cleaning the Data\n",
        "mobile_data = mobile_data.reset_index()\n",
        "mobile_data = mobile_data.drop(columns = [\"index\",\"Unnamed: 0\"])\n",
        "mobile_data = mobile_data.drop_duplicates()\n",
        "mobile_data = mobile_data.dropna(axis=0, subset=['Bug ID'])\n",
        "\n",
        "#To show Data\n",
        "mobile_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "v5viW4TBJ8Kb",
        "outputId": "6af11d21-3515-4171-e591-f8f60934b50a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Bug ID         Type                                            Summary  \\\n",
              "0  1668376       defect  Test failure in dom/base/test/test_window_clos...   \n",
              "1  1631754       defect  PanZoomController erroneously returns INPUT_RE...   \n",
              "2  1677838       defect  NumberFormatExceptionjava.lang.Integer in pars...   \n",
              "3  1686100  enhancement  Route Service.onTrimMemory notifications throu...   \n",
              "4  1630229       defect  Crash in [@ java.lang.AssertionError: at org.m...   \n",
              "\n",
              "     Product Component    Status Resolution              Updated   Bug Id  \\\n",
              "0  GeckoView   General  RESOLVED      FIXED  2020-10-14 03:01:38  1668376   \n",
              "1  GeckoView   General  RESOLVED      FIXED  2020-05-23 04:47:46  1631754   \n",
              "2  GeckoView   General  RESOLVED      FIXED  2021-01-06 13:28:48  1677838   \n",
              "3  GeckoView   General  RESOLVED      FIXED  2021-01-12 02:17:23  1686100   \n",
              "4  GeckoView   General  RESOLVED      FIXED  2020-05-28 05:17:09  1630229   \n",
              "\n",
              "                                         Description  Duplicate_Bug_Ids  \n",
              "0  the symptom was that the  broadcastchannel  me...                NaN  \n",
              "1  for websites which have their own event handle...                NaN  \n",
              "2  we are seeing these crash being reported on se...                NaN  \n",
              "3  since android may send these to the services h...                NaN  \n",
              "4  this bug is for crash report bp   ebbf        ...                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f360e6-3ba5-4da5-9f0d-1e998eb6112a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bug ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Product</th>\n",
              "      <th>Component</th>\n",
              "      <th>Status</th>\n",
              "      <th>Resolution</th>\n",
              "      <th>Updated</th>\n",
              "      <th>Bug Id</th>\n",
              "      <th>Description</th>\n",
              "      <th>Duplicate_Bug_Ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1668376</td>\n",
              "      <td>defect</td>\n",
              "      <td>Test failure in dom/base/test/test_window_clos...</td>\n",
              "      <td>GeckoView</td>\n",
              "      <td>General</td>\n",
              "      <td>RESOLVED</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2020-10-14 03:01:38</td>\n",
              "      <td>1668376</td>\n",
              "      <td>the symptom was that the  broadcastchannel  me...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1631754</td>\n",
              "      <td>defect</td>\n",
              "      <td>PanZoomController erroneously returns INPUT_RE...</td>\n",
              "      <td>GeckoView</td>\n",
              "      <td>General</td>\n",
              "      <td>RESOLVED</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2020-05-23 04:47:46</td>\n",
              "      <td>1631754</td>\n",
              "      <td>for websites which have their own event handle...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1677838</td>\n",
              "      <td>defect</td>\n",
              "      <td>NumberFormatExceptionjava.lang.Integer in pars...</td>\n",
              "      <td>GeckoView</td>\n",
              "      <td>General</td>\n",
              "      <td>RESOLVED</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2021-01-06 13:28:48</td>\n",
              "      <td>1677838</td>\n",
              "      <td>we are seeing these crash being reported on se...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1686100</td>\n",
              "      <td>enhancement</td>\n",
              "      <td>Route Service.onTrimMemory notifications throu...</td>\n",
              "      <td>GeckoView</td>\n",
              "      <td>General</td>\n",
              "      <td>RESOLVED</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2021-01-12 02:17:23</td>\n",
              "      <td>1686100</td>\n",
              "      <td>since android may send these to the services h...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1630229</td>\n",
              "      <td>defect</td>\n",
              "      <td>Crash in [@ java.lang.AssertionError: at org.m...</td>\n",
              "      <td>GeckoView</td>\n",
              "      <td>General</td>\n",
              "      <td>RESOLVED</td>\n",
              "      <td>FIXED</td>\n",
              "      <td>2020-05-28 05:17:09</td>\n",
              "      <td>1630229</td>\n",
              "      <td>this bug is for crash report bp   ebbf        ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f360e6-3ba5-4da5-9f0d-1e998eb6112a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48f360e6-3ba5-4da5-9f0d-1e998eb6112a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48f360e6-3ba5-4da5-9f0d-1e998eb6112a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To show Info\n",
        "mobile_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouXQWHvH9EjI",
        "outputId": "4989ba4b-d07c-40ba-e5d8-15488d4b7811"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5320 entries, 0 to 5319\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Bug ID             5320 non-null   int64  \n",
            " 1   Type               5320 non-null   object \n",
            " 2   Summary            5320 non-null   object \n",
            " 3   Product            5320 non-null   object \n",
            " 4   Component          5320 non-null   object \n",
            " 5   Status             5320 non-null   object \n",
            " 6   Resolution         5320 non-null   object \n",
            " 7   Updated            5320 non-null   object \n",
            " 8   Bug Id             5320 non-null   int64  \n",
            " 9   Description        5320 non-null   object \n",
            " 10  Duplicate_Bug_Ids  562 non-null    float64\n",
            "dtypes: float64(1), int64(2), object(8)\n",
            "memory usage: 498.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **On complete JDT data**"
      ],
      "metadata": {
        "id": "grF-2qVVK5pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Cleaning to Remove Punctuations\n",
        "def clean_text_round_1(text):\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    text = re.sub(r'\\w*\\f\\w*', '', text)\n",
        "    text = re.sub(r'\\(.*?\\)', '', text)\n",
        "    text = re.sub(r'\\[.*]\\)', '', text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text_round_1(x)\n",
        "\n",
        "#Text Cleaning to Remove Additional Punctuations\n",
        "def clean_text_round_2(text):\n",
        "    text = re.sub(r'[‘’“”…]', '', text)\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "    text = re.sub(r'\\t', '', text)\n",
        "    return text\n",
        "\n",
        "round2 = lambda x: clean_text_round_2(x)"
      ],
      "metadata": {
        "id": "jJQmEzp_LEfg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Clean Data in 'Description' Column\n",
        "mobile_data[\"Description\"]= mobile_data[\"Description\"].str.replace(\"fixed in HEAD\", \"\", case = False)\n",
        "mobile_data[\"Description\"]= mobile_data[\"Description\"].str.replace(\"has been marked as readonly\", \" \", case = False)\n",
        "\n",
        "mobile_data = mobile_data.dropna(axis=0, subset=['Description'])\n",
        "\n",
        "mobile_data['Description'] = mobile_data['Description'].apply(clean_text_round_1)\n",
        "mobile_data['Description'] = mobile_data['Description'].apply(clean_text_round_2)\n",
        "\n",
        "#To show Info\n",
        "mobile_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWHbWUCOLHLt",
        "outputId": "f3602fef-ce75-4a71-9f14-93267517ba99"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5320 entries, 0 to 5319\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Bug ID             5320 non-null   int64  \n",
            " 1   Type               5320 non-null   object \n",
            " 2   Summary            5320 non-null   object \n",
            " 3   Product            5320 non-null   object \n",
            " 4   Component          5320 non-null   object \n",
            " 5   Status             5320 non-null   object \n",
            " 6   Resolution         5320 non-null   object \n",
            " 7   Updated            5320 non-null   object \n",
            " 8   Bug Id             5320 non-null   int64  \n",
            " 9   Description        5320 non-null   object \n",
            " 10  Duplicate_Bug_Ids  562 non-null    float64\n",
            "dtypes: float64(1), int64(2), object(8)\n",
            "memory usage: 498.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Functions for Preprocessing\n",
        "def lemmatize(text):\n",
        "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 5:\n",
        "            result.append(lemmatize(token))\n",
        "    return result"
      ],
      "metadata": {
        "id": "mcLs5MXnLIbv"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Preprocess Data in 'Description' Column\n",
        "mobile_data['Description'] = mobile_data['Description'].map(preprocess)\n",
        "\n",
        "print('Null Duplicate Bug Ids: ',mobile_data['Duplicate_Bug_Ids'].isnull().sum())\n",
        "\n",
        "#To save Duplicate Reports in a CSV File\n",
        "duplicate_reports = mobile_data.dropna(axis=0, subset=['Duplicate_Bug_Ids'])\n",
        "duplicate_reports.reset_index(drop=True)\n",
        "duplicate_reports.to_csv('mobile_duplicate_reports.csv')\n",
        "\n",
        "#Seperating all the master reports into a dataframe\n",
        "master_reports = mobile_data[mobile_data.isnull().any(axis=1)]\n",
        "master_reports.reset_index(drop=True)\n",
        "\n",
        "print('NA Values in Master Report: ', master_reports.Description.isna().sum())\n",
        "\n",
        "#To save Master Reports in a CSV File\n",
        "master_reports.to_csv('mobile_master_reports.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwPul_AbLJlH",
        "outputId": "5928ca1d-6c07-40f3-9c1e-daaed50ce936"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Duplicate Bug Ids:  4758\n",
            "NA Values in Master Report:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Master Reports\n",
        "master_reports = pd.read_csv('mobile_master_reports.csv')\n",
        "master_reports = master_reports.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "#To Preprocess Data in 'Description' Column\n",
        "master_reports['Description'] = master_reports['Description'].map(preprocess)"
      ],
      "metadata": {
        "id": "uqeosVKfcC1Y"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Create a Dictionary\n",
        "dictionary = gensim.corpora.Dictionary(master_reports['Description'])\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "\n",
        "#To Create BoW a Dictionary\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in master_reports['Description']]"
      ],
      "metadata": {
        "id": "ugoAnV19Lfsq"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Open Pickle File\n",
        "file_bow = open('mobile_bow_corpus.pickle', 'wb')\n",
        "\n",
        "#To dump BoW data in Pickle File\n",
        "pickle.dump(bow_corpus, file_bow)\n",
        "\n",
        "#To Open Pickle File\n",
        "file_dict = open('mobile_dictionary.pickle', 'wb')\n",
        "\n",
        "#To dump Dictionary data in Pickle File\n",
        "pickle.dump(dictionary, file_dict)"
      ],
      "metadata": {
        "id": "CWyz-rCKMc61"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters for LDA Model\n",
        "corpus = bow_corpus\n",
        "no_of_topics = 10\n",
        "dictionary = dictionary\n",
        "p = 20\n",
        "k = 2\n",
        "epochs = 100\n",
        "\n",
        "#Training the LDA model on the BoW corpus\n",
        "lda_model = gensim.models.LdaMulticore(corpus, num_topics=no_of_topics, id2word=dictionary, passes=p, workers=k, iterations=epochs)"
      ],
      "metadata": {
        "id": "QQvR0qf-Meig"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the Model\n",
        "lda_model.save('mobile_lda_model.model')"
      ],
      "metadata": {
        "id": "d1mVcjWfMfsw"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation of Model\n",
        "\n",
        "#Perplexity\n",
        "print('Perplexity: ', lda_model.log_perplexity(bow_corpus))  \n",
        "\n",
        "#Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=mobile_data['Description'], dictionary=dictionary, coherence='c_v')\n",
        "print('\\nCoherence Score: ', coherence_model_lda.get_coherence())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGhi5UmVNKdJ",
        "outputId": "83293087-ea76-40fe-a105-49628dc84a05"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity:  -4.373968116529857\n",
            "\n",
            "Coherence Score:  0.598303448441005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)"
      ],
      "metadata": {
        "id": "KPD4vluDNMC4"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "T_mrYYeu_mF2",
        "outputId": "c222aa0f-b82d-4637-859c-b445f1477b1f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.379316 -0.120939       1        1  49.376022\n",
              "6     -0.105909 -0.165946       2        1   8.535589\n",
              "0      0.149609  0.150563       3        1   8.153274\n",
              "4      0.353330 -0.055031       4        1   7.485146\n",
              "8     -0.195395 -0.173743       5        1   5.400966\n",
              "3     -0.201053 -0.103612       6        1   5.337681\n",
              "7     -0.063543  0.230423       7        1   5.211858\n",
              "9     -0.036391  0.166236       8        1   3.710973\n",
              "1     -0.148099 -0.038763       9        1   3.447619\n",
              "2     -0.131866  0.110811      10        1   3.340872, topic_info=          Term          Freq         Total Category  logprob  loglift\n",
              "27     mozilla  19142.000000  19142.000000  Default  30.0000  30.0000\n",
              "37   geckoview  18121.000000  18121.000000  Default  29.0000  29.0000\n",
              "199    firefox   2029.000000   2029.000000  Default  28.0000  28.0000\n",
              "30      result   1805.000000   1805.000000  Default  27.0000  27.0000\n",
              "15     android   4643.000000   4643.000000  Default  26.0000  26.0000\n",
              "..         ...           ...           ...      ...      ...      ...\n",
              "199    firefox     88.020193   2029.956379  Topic10  -3.9762   0.2607\n",
              "282    example     55.325386    323.094394  Topic10  -4.4405   1.6342\n",
              "49      relate     41.776116    129.180556  Topic10  -4.7214   2.2701\n",
              "117     enable     45.066050    428.984296  Topic10  -4.6456   1.1456\n",
              "45      method     47.717705   1138.093043  Topic10  -4.5884   0.2271\n",
              "\n",
              "[551 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "76        1  0.201166      access\n",
              "76        2  0.026239      access\n",
              "76        3  0.293003      access\n",
              "76        5  0.074344      access\n",
              "76        6  0.139942      access\n",
              "...     ...       ...         ...\n",
              "629       6  0.041450   xcuitests\n",
              "629       7  0.273568   xcuitests\n",
              "629      10  0.613456   xcuitests\n",
              "437       2  0.987881     youtube\n",
              "55        1  0.998598  zygoteinit\n",
              "\n",
              "[1238 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 7, 1, 5, 9, 4, 8, 10, 2, 3])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1311404174355892001834931104\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1311404174355892001834931104_data = {\"mdsDat\": {\"x\": [0.37931590856758957, -0.10590853987388756, 0.14960914494542435, 0.3533295183820977, -0.195394998132187, -0.2010527326977776, -0.06354296561113058, -0.0363905414035433, -0.14809908216624187, -0.1318657120103443], \"y\": [-0.1209386800205446, -0.165945890658824, 0.15056333171986708, -0.055031126302800965, -0.1737428784241387, -0.10361201435387146, 0.23042322941955276, 0.16623585871099464, -0.038762855652612296, 0.11081102556237624], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [49.376021896148096, 8.535589407398696, 8.15327371821156, 7.485146417885241, 5.400966368827738, 5.33768065094945, 5.211858058060522, 3.7109728244947986, 3.447618514549084, 3.340872143474824]}, \"tinfo\": {\"Term\": [\"mozilla\", \"geckoview\", \"firefox\", \"result\", \"android\", \"libxul\", \"instrumentation\", \"status\", \"expect\", \"pointer\", \"previous\", \"dalvik\", \"actual\", \"reproduce\", \"create\", \"libart\", \"attachment\", \"thread\", \"process\", \"button\", \"screen\", \"search\", \"device\", \"safari\", \"framework\", \"toolbar\", \"method\", \"mobile\", \"internal\", \"string\", \"runners\", \"reflect\", \"evaluate\", \"zygoteinit\", \"handlecallback\", \"frameworkmethod\", \"uithreadutils\", \"activitythread\", \"looper\", \"errorcollector\", \"assertthat\", \"handlemessage\", \"statements\", \"syncrunnable\", \"progresstracker\", \"invokemethod\", \"checkthat\", \"geckoviewmodule\", \"internal\", \"assertionerror\", \"waituntilcalled\", \"mozafterpaint\", \"onevent\", \"pageshow\", \"basesessiontest\", \"timeoutrunnable\", \"invokenative\", \"hamcrest\", \"matcherassert\", \"dispatchmessage\", \"status\", \"geckoview\", \"handler\", \"instrumentation\", \"numtests\", \"lambda\", \"mozilla\", \"handleevent\", \"invoke\", \"android\", \"method\", \"stream\", \"current\", \"geckosession\", \"unexpected\", \"public\", \"safari\", \"applewebkit\", \"youtube\", \"internet\", \"originally\", \"apilint\", \"persist\", \"samsung\", \"chrome\", \"gradle\", \"sample\", \"resolve\", \"galaxy\", \"activate\", \"applications\", \"redirect\", \"connection\", \"bugzilla\", \"reddit\", \"behavior\", \"finger\", \"version\", \"unable\", \"couple\", \"reproduce\", \"capture\", \"filter\", \"websites\", \"result\", \"cookies\", \"actual\", \"firefox\", \"expect\", \"desktop\", \"mobile\", \"browser\", \"appear\", \"download\", \"github\", \"device\", \"attachment\", \"create\", \"support\", \"mozilla\", \"display\", \"android\", \"content\", \"update\", \"google\", \"select\", \"happen\", \"button\", \"components\", \"extensions\", \"package\", \"tinderboxprint\", \"libdispatch\", \"partial\", \"symbol\", \"toolkit\", \"cleanup\", \"javadoc\", \"resource\", \"deprecate\", \"geckoruntime\", \"buffer\", \"mozharness\", \"webextensions\", \"taskcluster\", \"ssltunnel\", \"dependency\", \"closure\", \"string\", \"mochitest\", \"manifest\", \"sqlite\", \"locales\", \"geckoappshell\", \"storage\", \"python\", \"usually\", \"modules\", \"bundle\", \"extension\", \"source\", \"dispatch\", \"central\", \"session\", \"return\", \"directory\", \"server\", \"framework\", \"listener\", \"application\", \"screenshots\", \"action\", \"geckothread\", \"android\", \"mobile\", \"update\", \"support\", \"worker\", \"exception\", \"message\", \"method\", \"public\", \"workspace\", \"geckoview\", \"change\", \"client\", \"process\", \"libxul\", \"pointer\", \"libart\", \"linearalloc\", \"mozcrash\", \"previous\", \"minidump\", \"blobber\", \"symbols\", \"stackwalk\", \"nsthread\", \"instruction\", \"uptime\", \"nsthreadutils\", \"sigsegv\", \"preempt\", \"messageloop\", \"maperr\", \"shortmsg\", \"family\", \"geckoloader\", \"messagepump\", \"libmozglue\", \"natives\", \"fastmult\", \"nativerun\", \"sigabrt\", \"unknown\", \"dalvik\", \"operate\", \"filename\", \"upload\", \"workspace\", \"framework\", \"worker\", \"process\", \"reason\", \"widget\", \"output\", \"mozilla\", \"artifacts\", \"thread\", \"public\", \"geckoview\", \"service\", \"instrumentation\", \"application\", \"android\", \"screenshot\", \"reader\", \"landscape\", \"library\", \"hamburger\", \"portrait\", \"overlap\", \"briefly\", \"attach\", \"property\", \"wikipedia\", \"favicons\", \"cursor\", \"reproducible\", \"orientation\", \"incorrect\", \"favicon\", \"screen\", \"attachment\", \"carthage\", \"number\", \"onboarding\", \"actors\", \"latest\", \"simulator\", \"smaller\", \"exactly\", \"article\", \"switch\", \"regular\", \"create\", \"master\", \"notice\", \"background\", \"iphone\", \"select\", \"launch\", \"display\", \"actual\", \"result\", \"expect\", \"firefox\", \"reproduce\", \"happen\", \"possible\", \"device\", \"scroll\", \"private\", \"button\", \"settings\", \"change\", \"bookmarks\", \"homepage\", \"cancel\", \"collection\", \"passwords\", \"fxscreengraph\", \"username\", \"requisites\", \"debugger\", \"logins\", \"password\", \"windows\", \"account\", \"management\", \"confirm\", \"corner\", \"camera\", \"prompt\", \"bookmark\", \"feedback\", \"toggle\", \"private\", \"settings\", \"delete\", \"notification\", \"devices\", \"twitter\", \"browse\", \"character\", \"connect\", \"button\", \"protection\", \"record\", \"device\", \"history\", \"firefox\", \"change\", \"result\", \"options\", \"expect\", \"enable\", \"select\", \"iphone\", \"actual\", \"desktop\", \"display\", \"reproduce\", \"message\", \"default\", \"corefoundation\", \"uitests\", \"better\", \"delegate\", \"sentry\", \"urlbar\", \"clients\", \"folder\", \"convert\", \"database\", \"cfrunlooprun\", \"tabmanager\", \"libdyld\", \"gseventrunmodal\", \"discussion\", \"backtrace\", \"channel\", \"privacy\", \"generate\", \"handle\", \"forward\", \"parameter\", \"experience\", \"origin\", \"external\", \"implementation\", \"events\", \"socorro\", \"special\", \"restore\", \"webview\", \"feature\", \"currently\", \"webkit\", \"report\", \"disable\", \"request\", \"notifications\", \"client\", \"commit\", \"release\", \"description\", \"enable\", \"change\", \"modify\", \"exception\", \"geckosession\", \"implement\", \"content\", \"mobile\", \"provide\", \"browser\", \"support\", \"default\", \"update\", \"master\", \"toolbar\", \"disappear\", \"variant\", \"viewport\", \"dependencies\", \"suggestions\", \"surface\", \"expand\", \"libraries\", \"revision\", \"elements\", \"dynamic\", \"regress\", \"search\", \"determine\", \"suggestion\", \"static\", \"migrate\", \"engine\", \"fullscreen\", \"alamofire\", \"compositor\", \"notify\", \"animation\", \"keyboard\", \"position\", \"produce\", \"dependent\", \"compilation\", \"success\", \"ensure\", \"migration\", \"project\", \"thread\", \"google\", \"visible\", \"render\", \"review\", \"content\", \"directly\", \"information\", \"module\", \"scroll\", \"address\", \"instead\", \"command\", \"display\", \"android\", \"create\", \"example\", \"current\", \"counter\", \"unresponsive\", \"sessions\", \"approach\", \"examples\", \"remote\", \"intent\", \"preview\", \"window\", \"production\", \"failures\", \"fission\", \"leanplum\", \"easily\", \"reporter\", \"developer\", \"intermittent\", \"policy\", \"second\", \"proper\", \"switcher\", \"script\", \"wonder\", \"scheme\", \"fennec\", \"common\", \"people\", \"identify\", \"recently\", \"anymore\", \"development\", \"option\", \"widget\", \"launch\", \"website\", \"include\", \"relate\", \"problem\", \"continue\", \"disable\", \"download\", \"reload\", \"active\", \"button\", \"github\", \"device\", \"firefox\", \"enable\", \"location\", \"update\", \"iphone\", \"happen\", \"display\", \"scroll\", \"metadata\", \"stories\", \"locale\", \"header\", \"topsites\", \"integration\", \"schema\", \"initially\", \"confuse\", \"section\", \"scenario\", \"investigate\", \"custom\", \"reality\", \"memory\", \"measure\", \"highlight\", \"intermittently\", \"compile\", \"scenarios\", \"shouldn\", \"associate\", \"solution\", \"enterprise\", \"decide\", \"upgrade\", \"smoketest\", \"pocket\", \"things\", \"xcuitests\", \"element\", \"verify\", \"branch\", \"correctly\", \"process\", \"follow\", \"history\", \"profile\", \"remove\", \"configuration\", \"activity\", \"option\", \"different\", \"appear\", \"create\", \"desktop\", \"correct\", \"access\", \"fennec\", \"change\", \"firefox\", \"example\", \"relate\", \"enable\", \"method\"], \"Freq\": [19142.0, 18121.0, 2029.0, 1805.0, 4643.0, 953.0, 3447.0, 3417.0, 1239.0, 686.0, 679.0, 670.0, 1014.0, 963.0, 915.0, 536.0, 611.0, 523.0, 645.0, 641.0, 552.0, 382.0, 696.0, 449.0, 602.0, 302.0, 1138.0, 868.0, 1576.0, 404.0, 1231.5647026542026, 846.4020949106309, 684.7089664700624, 674.9857748288067, 510.7706479398709, 504.9736652976521, 503.0613605312631, 419.0513906790867, 376.7009158960249, 342.4463296692462, 336.7101258558575, 324.6270234080509, 296.5561824452067, 285.08400088208583, 256.40244895080855, 239.19261030793476, 231.545474257501, 221.9849838594153, 1568.9094214890777, 190.43550764288815, 189.47962976556246, 186.61149556406, 177.05095672376217, 149.3257509445279, 134.02926664930607, 129.24903759766727, 129.24903759766727, 121.60073893414217, 121.60073893414217, 533.2333017086049, 3367.662542323222, 17547.96528360219, 1068.1583346443272, 3319.560588282544, 405.6276338629364, 561.6600637514365, 16951.82792862737, 550.42889834111, 783.564407475045, 3421.968199819236, 898.3538484343992, 409.58484587774205, 424.3180279828106, 416.1346850862131, 315.43543660280574, 333.4447009252011, 445.7558679395474, 310.3353204124638, 75.87085049391614, 33.516471791825936, 30.708042858637562, 24.31545002839537, 16.382956175967525, 16.476180144719983, 298.5940969333013, 125.5501007931983, 38.28472552332538, 48.627796033876926, 12.024479526985832, 29.27420758345528, 10.90964750595787, 50.77237998024789, 54.42271092689624, 28.072121673717056, 12.0501170255937, 122.18000282169731, 28.92589266687986, 314.51771215008046, 45.977105617628176, 22.590533050498674, 653.5696214109674, 15.120432539504032, 18.76945013832778, 24.771626949838403, 1107.4964388768853, 13.765202736671636, 597.2842622592302, 1128.8257658258265, 662.0341802414449, 151.04144235091528, 349.47800959299565, 175.70234612368583, 134.06588716730374, 93.94321999000982, 49.32043976566002, 158.16964115814432, 133.02416367876683, 157.13533159484038, 107.11727384485015, 579.911827599102, 97.15561573260884, 199.92241164939415, 77.9492506423675, 69.28448791672393, 58.176004993327886, 64.67438303612845, 58.627511923462635, 58.97576542951278, 192.80704981270992, 119.46608057348352, 84.79370679930632, 76.97369152747835, 64.65733625488, 64.46499044252887, 62.329482112958935, 49.67278743283441, 47.53745508296471, 43.09595408968863, 210.21483377420108, 36.65154547096574, 37.69412653954057, 34.45640935296797, 29.65091568063939, 28.339272315849637, 28.079414291228552, 17.98695715217915, 19.214786185195837, 64.67208122067197, 377.573469802122, 103.92524925357529, 38.13293992114076, 28.689447922075008, 90.76999874998167, 19.998867739108167, 89.39875426035502, 35.85605856602716, 14.633338668491591, 131.0385696532107, 78.82638981334269, 161.96699130315434, 174.97905832337923, 79.79984552239544, 227.57172227329855, 156.59488565783147, 202.61259604776654, 64.04263916197745, 106.10634165822292, 301.4973387384337, 76.09465692667615, 159.75511844912108, 81.24297505320686, 148.80554418102537, 83.87577001931696, 804.3483040837539, 279.17622287740045, 196.61401333506208, 189.16665907570248, 136.91038298913145, 108.76189666556273, 137.4733153865755, 169.03738637918545, 128.60330923424942, 103.5654400919419, 248.84660148743856, 115.37370997366781, 99.41416428701291, 105.78920490753615, 952.9400324491454, 685.0638056493528, 535.683090984338, 203.3349791308628, 180.36872739571695, 675.4535389335837, 153.93363012253968, 123.04233731185596, 104.81172903052806, 94.76108216465288, 80.574948838036, 63.7333406350568, 61.43708949484295, 57.78867370238985, 53.78194477842097, 49.18880115817133, 41.71275670668318, 41.53367602464468, 38.06400555714761, 34.23677345174292, 33.6503024546381, 33.47134416569539, 32.11948060047178, 25.050633082958598, 22.167700429515172, 22.16757314069555, 23.02700032431106, 74.2403570850722, 599.1148697185357, 61.34636194079452, 68.94792785560276, 127.40613095776355, 161.69661294780175, 291.14787378755767, 169.51839341628215, 279.6556124993149, 99.96197604564166, 115.76303241826713, 71.05411720522368, 1435.8192953193911, 145.84227151699244, 130.59556774527417, 126.4633026708137, 290.39957219133527, 98.39494297015443, 126.88001689191742, 80.29726338230391, 100.31049283377028, 147.1433314590127, 115.9294820931212, 47.75732673398227, 211.37248842049667, 18.38671857673299, 25.82476177869675, 14.38634806536603, 12.138535603471773, 188.70205011664933, 31.213284158195318, 22.95182872167261, 26.844548362202822, 26.908847802741327, 83.46075153503895, 28.240666126302695, 23.11071920271763, 32.22258967148505, 420.4192036919161, 456.66930797437794, 8.155245845311265, 86.16387147228909, 16.99571240973559, 10.185082426619406, 113.20651630063837, 24.721167257763156, 5.514980094857725, 9.292645085299537, 42.98537706634564, 86.32017259557591, 18.087764329748428, 501.70095945148375, 168.1195031727427, 54.07023040414306, 89.0240838236007, 165.7970364886882, 140.4285792470489, 72.39522123535524, 150.07008995145523, 257.07567729164543, 340.57731453840796, 227.71822434352512, 304.68673887149646, 184.80078877481034, 83.70578320153236, 53.50595176809761, 117.39143418990956, 74.1327615397126, 66.40038113113258, 89.14948221609801, 57.29014446586197, 56.27663522033178, 225.29157035705413, 85.89002298640231, 72.48050853001116, 49.81826236112163, 37.69316846520686, 27.743108108838175, 20.464675474768622, 19.547339445634165, 19.854365628257852, 70.89227714116149, 83.61131085526989, 42.853050965177744, 141.45209852276133, 34.79627742298129, 44.378710373321915, 11.871493739276213, 34.12329086109889, 56.95931977035321, 81.84810973317255, 19.34762265635619, 32.53659558068588, 199.02344578814996, 325.7587736456705, 78.08768136865132, 59.17904533751753, 125.58363753943898, 30.51362804848118, 117.49024526680564, 33.26175746208197, 43.41937225191117, 369.3676353467114, 51.49144403767464, 58.23472965838631, 279.2506888105047, 105.18507407709127, 361.9361103055723, 160.02186205045487, 264.427214467404, 68.1603013042345, 183.92749373762845, 107.61560259794412, 101.95215931434434, 96.34796094022246, 137.8675336273055, 85.1646656002961, 94.20142395775436, 102.88241960128005, 75.05328069209956, 66.76451637325516, 112.09087735311377, 90.42889343090413, 72.23612698562874, 55.72540124570309, 61.32442685046983, 35.406947984574956, 33.194754523470856, 43.74470982325022, 27.369987378654688, 26.94229132501932, 20.73354505418042, 18.909196366563886, 19.096958090714356, 16.438566987248812, 13.797158825291017, 16.314919105707286, 22.181679999305864, 22.555875696559582, 36.372211064895936, 127.87860429814887, 25.81909404728268, 9.427109986858193, 34.21322650262653, 28.336475944216943, 15.871959880534192, 58.25321425484404, 142.21119790807148, 22.17518952948837, 17.534721777032626, 64.60882274517463, 62.5241206554856, 177.06245736514686, 207.4752853959972, 39.20262177611637, 180.235478979454, 115.98383660585344, 122.51522638116771, 56.76962716365665, 158.44933073338277, 84.28521377909958, 100.0035704191, 43.34660949385618, 156.5143526013219, 218.50900227309276, 51.57490942270499, 82.77479554929165, 142.12406744140387, 58.307885554703795, 92.75081128406994, 121.28874575271398, 51.2236263792739, 76.45101217777204, 76.77897179972662, 62.39587933482692, 72.41552166242258, 62.776792191101315, 299.92215434232463, 30.8804342430333, 74.19654540377365, 19.436970935026665, 22.771557258613132, 15.754238910367924, 59.84995367362481, 11.230439464345487, 14.868503848588619, 17.56538879187439, 79.37436061063548, 30.087470154364095, 13.863162763303354, 329.34855409818874, 27.685335084214774, 9.391569820443408, 120.13853032365485, 30.182026328230904, 83.18421931759646, 28.236225464835815, 13.830663857073676, 92.98805158036186, 50.13417513356752, 24.810606038624364, 85.55445135749947, 49.637236408174324, 10.457263069991788, 7.560189888621559, 11.701091685054603, 22.251904857242696, 50.66177902056538, 42.71478370095633, 34.98979405424051, 301.85196728269534, 131.68738843772283, 102.89202013465508, 56.55104830683504, 30.275385895744133, 163.4924474490267, 41.66052253239244, 55.039921376159036, 39.75228248709394, 67.58195305492305, 58.629206454341606, 53.86823744456595, 43.55542272268229, 65.59059134393564, 55.707681119710664, 42.251815974599, 37.91678542844196, 36.73637088213524, 70.23721649889448, 38.96936081731373, 28.103181186609238, 18.718443576381546, 14.491571939432555, 62.63079334380831, 17.531880619823085, 41.92285527027194, 168.49578676624824, 27.85909925255928, 61.48416770545018, 13.590886309213772, 81.74665506549962, 24.674330949079874, 11.009617764033061, 17.031901971151175, 15.85826661016849, 8.329981784384893, 148.2640027275593, 14.183536403093695, 20.384648966593577, 74.29092983686189, 15.593040063574662, 40.44201982980733, 187.86951038650437, 20.649880023075973, 19.793553656796945, 9.14578567442209, 30.13080453664924, 38.43925047565712, 20.74910208142678, 137.48426864089683, 101.53606413470399, 71.9869540451346, 89.31871286970934, 67.53748445579414, 53.26443127454468, 54.889087061393866, 27.904820502846107, 66.54291873023153, 71.25418284096672, 38.95589879994282, 35.16401831742298, 121.6187512573856, 40.50588887168561, 104.1611620319179, 139.92055554338708, 70.22487293388807, 45.62995210268652, 63.39982856193912, 57.45428912855654, 45.88356117633313, 46.390711675297865, 42.36533396719356, 38.365396222332265, 30.396508617093517, 29.610049025508744, 26.00481197315991, 25.58417086540043, 37.74223327506274, 44.36288508361239, 46.03514883111466, 17.30945303791975, 68.20362265065016, 20.9307289144416, 46.91444786720067, 83.6687332757236, 10.899636380401436, 24.54924934719204, 13.654088104652503, 63.874634750056785, 24.266917968976898, 22.402714946742496, 27.223653354013923, 17.99305547527288, 12.911803018446713, 31.26218557826201, 37.99073453395272, 21.900970705739724, 19.51224569002577, 27.784426586325953, 46.45209707608771, 57.50365105763259, 74.10590557606946, 89.07071414324015, 54.90229362482704, 33.15918297014064, 65.88780436089435, 216.77791559935113, 103.420374804976, 89.77782088743484, 77.6828343222655, 90.56871409948926, 42.22640007721894, 36.12860738133199, 85.86946972434913, 57.48722765129956, 81.3653133903762, 129.18499336795244, 72.78580983083815, 47.121409882558076, 56.70644720195262, 61.09327101510887, 72.16542199347322, 88.02019301116648, 55.32538644385656, 41.77611555137619, 45.066049860667015, 47.71770452164893], \"Total\": [19142.0, 18121.0, 2029.0, 1805.0, 4643.0, 953.0, 3447.0, 3417.0, 1239.0, 686.0, 679.0, 670.0, 1014.0, 963.0, 915.0, 536.0, 611.0, 523.0, 645.0, 641.0, 552.0, 382.0, 696.0, 449.0, 602.0, 302.0, 1138.0, 868.0, 1576.0, 404.0, 1232.5269223194582, 847.3643091817614, 685.6710935513958, 675.9478539908857, 511.7327075887702, 505.9357282849326, 504.0234173047234, 420.0135895729666, 377.6630103359636, 343.408364491345, 337.6721731911992, 325.5892086886039, 297.5183329915904, 286.04604129614734, 257.36462014998006, 240.1555876952354, 232.50750814209675, 222.9470984479456, 1576.6162674619045, 191.3977380106593, 190.44167227669922, 187.57356344632473, 178.0130866262348, 150.28791524763898, 134.99130083681754, 130.21107644251444, 130.2110770977555, 122.5627789632604, 122.56277941535244, 537.4645479078765, 3417.9162830526498, 18121.142789847265, 1085.7050398274455, 3447.256288559596, 413.05505354672704, 578.5712012731964, 19142.470641787197, 577.3350966285635, 844.539469364761, 4643.126083115171, 1138.0930434709728, 464.7461075638866, 555.2969515212504, 605.144580509374, 378.4869734671844, 612.3919963511152, 449.5687191355406, 313.1988922786639, 76.93237589190463, 34.57485605355596, 31.795018531732428, 25.3735824853353, 17.440570022039743, 17.943829057997664, 330.5076124328797, 140.02532302838048, 43.64210422811933, 55.69507534839641, 13.976489140549804, 34.71550436992678, 12.984118833474046, 61.17256093094233, 68.18533482225507, 36.02899843788141, 15.771742759055435, 161.02415024331472, 39.479853535492545, 444.2826877739743, 64.97028257934187, 33.12290631275095, 963.9178299849025, 22.740716797266334, 28.620093456930515, 40.0206749762379, 1805.3871948827489, 23.06711116111752, 1014.5754341239001, 2029.956378719194, 1239.7395093697826, 321.24645953384606, 868.1657452832912, 431.3999127579829, 326.9016663338242, 229.5785356054159, 100.38106532197615, 696.3179084346489, 611.8610363103389, 915.2469019729942, 475.1344251844718, 19142.470641787197, 475.6316085747072, 4643.126083115171, 440.40658027452474, 490.6185090790112, 214.28626688433167, 397.9343028363215, 296.7759696925697, 641.2528133480439, 194.38910151917395, 120.4802350052799, 85.82675522781042, 78.04899555860226, 65.65587859147584, 65.4714236843927, 63.327215875244185, 50.66946349171711, 48.5681524520797, 44.09261006299265, 215.8824915127156, 37.64813193020342, 38.80182412968408, 35.5119800631908, 30.655994303562405, 29.336080095887723, 29.10772631322868, 19.014266311896638, 20.44352438246918, 69.1082414338712, 404.86210100210263, 111.75867504041106, 41.0107893923977, 30.99874021387643, 98.27882090839466, 22.098823716985223, 99.07865426761313, 40.65453134735879, 16.62203532998344, 151.03232083021538, 91.72989926083962, 197.0392140036678, 213.84421898972673, 96.0102877406715, 315.97943190612, 215.0993829627547, 310.31689063388666, 78.98717029308227, 148.70516966121954, 602.2690972306406, 100.6812228790243, 277.96893878711415, 111.49456176969727, 272.607189462204, 117.8781571344671, 4643.126083115171, 868.1657452832912, 490.6185090790112, 475.1344251844718, 308.5384903673298, 217.1863652198356, 441.92174686851706, 1138.0930434709728, 612.3919963511152, 266.11269634306336, 18121.142789847265, 704.4488377719497, 318.8893835769818, 645.1164477396916, 953.9393891951635, 686.0882132278576, 536.6827848330022, 204.33370361778532, 181.3680465006307, 679.4256691763594, 154.93324379811094, 124.08512916633595, 105.89236241732374, 95.76027857273564, 81.57370772414717, 64.73235043099713, 62.43579635565747, 58.78736371628546, 54.78059112706323, 50.187483074676216, 42.71144375855134, 42.532295797658, 39.06316725026157, 35.23544326810195, 34.649144026030115, 34.469947529767225, 33.1180840155975, 26.04923410393995, 23.166339125375988, 23.166361976765877, 24.112271273901985, 81.48109705627698, 670.0172460675635, 70.97099781416826, 85.25514044612596, 189.82444065074606, 266.11269634306336, 602.2690972306406, 308.5384903673298, 645.1164477396916, 176.01909867288208, 227.15806743267868, 107.68867626679301, 19142.470641787197, 448.7408239898501, 523.9283506740485, 612.3919963511152, 18121.142789847265, 443.4507772420942, 3447.256288559596, 277.96893878711415, 4643.126083115171, 148.27132874157422, 116.99458667502243, 48.80420395601015, 222.53617587079333, 19.433616226934326, 27.36735456399776, 15.43719138020271, 13.367780369659684, 209.63254982545095, 34.75670634838306, 26.18474595738687, 30.868167302553303, 31.371191237814035, 100.1404953053706, 35.332951265570834, 29.180073312432217, 41.69329852859931, 552.1948620839595, 611.8610363103389, 11.053069167570309, 119.3409795862197, 24.897965954726182, 15.706950755667311, 178.77557961805908, 40.30631305132553, 9.037618207797882, 15.581328411253546, 72.08332684052809, 145.04598507969393, 30.725834310228507, 915.2469019729942, 314.0099783431163, 96.49308274890078, 178.18049572171904, 377.86317947933946, 397.9343028363215, 172.8985796736247, 475.6316085747072, 1014.5754341239001, 1805.3871948827489, 1239.7395093697826, 2029.956378719194, 963.9178299849025, 296.7759696925697, 127.90189530234635, 696.3179084346489, 275.63366015238665, 280.0682303050547, 641.2528133480439, 459.04958452951786, 704.4488377719497, 226.34693818593394, 86.94567838759349, 73.53834113796208, 50.87583946880659, 38.7479266319257, 28.797928294377556, 21.519370600631476, 20.60195875333394, 21.078519784663385, 78.45175569975923, 92.53252661124986, 48.92479172709718, 168.6632981655689, 41.81765633009089, 54.26856230907591, 15.06703207983449, 44.47672426969623, 76.61621349162593, 110.97976165707553, 26.601884045628672, 44.78823934737875, 280.0682303050547, 459.04958452951786, 111.71410524638861, 86.1078853937323, 183.3306504772423, 45.29315449954303, 176.73155463327907, 52.38782476193697, 71.96302168226912, 641.2528133480439, 87.64971070637533, 102.58207398333697, 696.3179084346489, 229.82231425086994, 2029.956378719194, 704.4488377719497, 1805.3871948827489, 165.64773565889857, 1239.7395093697826, 428.98429556785663, 397.9343028363215, 377.86317947933946, 1014.5754341239001, 321.24645953384606, 475.6316085747072, 963.9178299849025, 441.92174686851706, 237.65467517220557, 113.13229988183573, 91.46867915975528, 73.2768434069935, 56.784868627635156, 62.861439725617146, 36.446384741134054, 34.234195959426756, 45.13306628695045, 28.409591217417052, 27.98523354800113, 21.772982321557663, 19.94903019694074, 20.286428808006875, 17.47803472933609, 14.841420324969066, 18.471256467196064, 25.771003737362427, 26.40928470777986, 42.927219487570085, 151.6348007310566, 30.94852115023386, 11.345294632057502, 41.643512339956786, 35.584273500497055, 19.980992597062865, 73.52532170820324, 180.52875795862897, 28.303727697208934, 23.047131877654117, 85.92590699711529, 83.28751600661248, 261.3862301907273, 319.7293040779207, 53.35806575624444, 310.97870923597657, 200.3358272817997, 224.71149060207458, 85.02081154561401, 318.8893835769818, 148.43080883892975, 197.07933596696944, 65.32336552569363, 428.98429556785663, 704.4488377719497, 89.82578710217174, 217.1863652198356, 605.144580509374, 115.26818341616952, 440.40658027452474, 868.1657452832912, 106.46908528339918, 431.3999127579829, 475.1344251844718, 237.65467517220557, 490.6185090790112, 314.0099783431163, 302.1840723150869, 32.13765957472366, 78.14514362366572, 20.519188963297925, 24.35722286172099, 16.87737936214053, 64.1255353752217, 12.288508921145265, 16.4446570917979, 19.600402624344568, 88.97115449870333, 34.72728300830437, 16.017073444818518, 382.2177100056967, 32.18256833182553, 10.9972011861779, 142.9975714924465, 36.28894320283814, 100.029963672583, 34.07617935048434, 16.78702819118094, 116.49582332629409, 63.52006442825648, 31.454216529363315, 109.91392601218666, 64.61628206906147, 13.669934936045083, 10.195417488045635, 15.96293252107263, 30.458953619058413, 69.69264283262947, 58.67437547292352, 50.048094049491255, 523.9283506740485, 214.28626688433167, 164.03079272555448, 91.8792983214934, 44.82580790864524, 440.40658027452474, 69.0649764231379, 125.00786796544459, 90.15414854846428, 275.63366015238665, 206.64797843794275, 219.97613321387746, 124.4627659381438, 475.6316085747072, 4643.126083115171, 915.2469019729942, 323.0943943619999, 555.2969515212504, 71.2892149562729, 40.023156671132966, 29.503708740006275, 19.83403094335687, 15.559255488393035, 67.29710767254139, 19.060859431814535, 46.59335848659653, 188.76928021011952, 32.795635986206946, 72.820040647695, 16.88400697198823, 101.82340647830829, 31.393805764681403, 14.996899356677494, 23.213093131533206, 22.088068240001398, 11.932907914957648, 216.48775827881067, 21.06271159224874, 30.811179083562095, 114.2466287351396, 24.074002574207235, 64.65581585197604, 301.51310790829746, 33.28472010826285, 32.09738126363792, 14.963096751532378, 50.04034493735045, 64.68361134488579, 35.19726939620692, 317.66762909826, 227.15806743267868, 172.8985796736247, 242.12169028529826, 168.26988044499473, 129.18055580624355, 144.0250138374529, 52.532974503973044, 200.3358272817997, 229.5785356054159, 90.68012006319813, 76.88543776987328, 641.2528133480439, 100.38106532197615, 696.3179084346489, 2029.956378719194, 428.98429556785663, 158.557421157948, 490.6185090790112, 377.86317947933946, 296.7759696925697, 475.6316085747072, 275.63366015238665, 39.412992041091364, 31.44730080462949, 30.656997272793205, 27.051601646410933, 26.657353842192464, 39.784097110442275, 48.80288846948388, 50.69435685497272, 19.7984919583946, 82.28126088012216, 25.69518574897841, 58.89810396928105, 107.39228832272774, 14.60452852495036, 33.594757654440805, 18.703719721354002, 88.84607403297333, 33.88636460456396, 31.774307285247115, 38.752075057136324, 25.655398870518024, 18.846062112322585, 46.45367989039289, 56.994040283154426, 32.94133004956508, 30.21134746760564, 43.11209230596036, 74.05186557705089, 93.51992186662383, 120.6280806248283, 148.91611105257817, 98.314237808518, 56.214362162259064, 139.8351095509268, 645.1164477396916, 253.65783891439858, 229.82231425086994, 196.26346751069238, 296.07369554983956, 87.8868740794666, 67.17657085374336, 317.66762909826, 158.88653355228473, 326.9016663338242, 915.2469019729942, 321.24645953384606, 124.1151659569108, 228.66635783010875, 301.51310790829746, 704.4488377719497, 2029.956378719194, 323.0943943619999, 129.18055580624355, 428.98429556785663, 1138.0930434709728], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0309, -4.406, -4.618, -4.6323, -4.911, -4.9225, -4.9262, -5.109, -5.2155, -5.3108, -5.3277, -5.3643, -5.4547, -5.4942, -5.6002, -5.6697, -5.7022, -5.7443, -3.7888, -5.8976, -5.9027, -5.9179, -5.9705, -6.1408, -6.2489, -6.2852, -6.2852, -6.3462, -6.3462, -4.868, -3.025, -1.3743, -4.1733, -3.0394, -5.1415, -4.8161, -1.4088, -4.8363, -4.4831, -3.009, -4.3464, -5.1318, -5.0965, -5.1159, -5.393, -5.3375, -3.292, -3.6541, -5.0627, -5.8797, -5.9672, -6.2006, -6.5955, -6.5898, -3.6927, -4.559, -5.7467, -5.5075, -6.9048, -6.015, -7.0021, -5.4644, -5.395, -6.057, -6.9027, -4.5862, -6.027, -3.6407, -5.5636, -6.2742, -2.9093, -6.6757, -6.4595, -6.182, -2.3819, -6.7696, -2.9993, -2.3628, -2.8964, -4.3742, -3.5353, -4.2229, -4.4934, -4.849, -5.4934, -4.3281, -4.5012, -4.3346, -4.7178, -3.0289, -4.8154, -4.0938, -5.0357, -5.1535, -5.3283, -5.2224, -5.3205, -5.3146, -4.0842, -4.5629, -4.9057, -5.0024, -5.1768, -5.1798, -5.2135, -5.4405, -5.4844, -5.5825, -3.9978, -5.7445, -5.7164, -5.8062, -5.9564, -6.0017, -6.0109, -6.4563, -6.3902, -5.1766, -3.4121, -4.7022, -5.7048, -5.9894, -4.8376, -6.3502, -4.8528, -5.7664, -6.6626, -4.4704, -4.9787, -4.2585, -4.1812, -4.9664, -3.9184, -4.2923, -4.0346, -5.1864, -4.6815, -3.6372, -5.0139, -4.2723, -4.9485, -4.3433, -4.9166, -2.6559, -3.7141, -4.0647, -4.1033, -4.4266, -4.6568, -4.4225, -4.2158, -4.4892, -4.7057, -3.8291, -4.5977, -4.7466, -4.6845, -2.4009, -2.7309, -2.9769, -3.9456, -4.0654, -2.745, -4.2239, -4.4479, -4.6082, -4.7091, -4.8712, -5.1057, -5.1424, -5.2036, -5.2755, -5.3647, -5.5296, -5.5339, -5.6211, -5.7271, -5.7444, -5.7497, -5.791, -6.0395, -6.1618, -6.1618, -6.1237, -4.9531, -2.865, -5.1439, -5.0271, -4.413, -4.1747, -3.5866, -4.1275, -3.6269, -4.6556, -4.5089, -4.997, -1.9909, -4.2779, -4.3883, -4.4205, -3.5892, -4.6714, -4.4172, -4.8747, -4.6521, -3.9427, -4.1811, -5.0679, -3.5804, -6.0224, -5.6827, -6.2678, -6.4377, -3.6939, -5.4932, -5.8007, -5.644, -5.6416, -4.5097, -5.5933, -5.7938, -5.4614, -2.8928, -2.8101, -6.8354, -4.4778, -6.1011, -6.6131, -4.2049, -5.7264, -7.2266, -6.7048, -5.1732, -4.476, -6.0388, -2.7161, -3.8094, -4.9438, -4.4452, -3.8233, -3.9894, -4.6519, -3.923, -3.3847, -3.1034, -3.506, -3.2148, -3.7148, -4.5068, -4.9543, -4.1686, -4.6282, -4.7384, -4.4438, -4.8859, -4.9038, -3.5049, -4.4692, -4.639, -5.0139, -5.2928, -5.5993, -5.9036, -5.9494, -5.9339, -4.6611, -4.4961, -5.1645, -3.9703, -5.3728, -5.1295, -6.4481, -5.3923, -4.8799, -4.5174, -5.9597, -5.4399, -3.6289, -3.1361, -4.5645, -4.8417, -4.0893, -5.5041, -4.1559, -5.4179, -5.1514, -3.0105, -4.9809, -4.8578, -3.2902, -4.2666, -3.0308, -3.847, -3.3447, -4.7004, -3.7077, -4.2437, -4.2978, -4.3543, -3.996, -4.4777, -4.3768, -4.2887, -4.6041, -4.7211, -4.1791, -4.3939, -4.6185, -4.878, -4.7823, -5.3315, -5.396, -5.1201, -5.589, -5.6047, -5.8667, -5.9588, -5.9489, -6.0988, -6.274, -6.1064, -5.7992, -5.7824, -5.3046, -4.0473, -5.6473, -6.6548, -5.3658, -5.5543, -6.1339, -4.8336, -3.9411, -5.7995, -6.0342, -4.7301, -4.7629, -3.7219, -3.5634, -5.2297, -3.7042, -4.145, -4.0902, -4.8594, -3.833, -4.4642, -4.2932, -5.1292, -3.8453, -3.5116, -4.9554, -4.4823, -3.9417, -4.8327, -4.3685, -4.1003, -4.9622, -4.5618, -4.5575, -4.7649, -4.616, -4.7588, -2.8553, -5.1287, -4.2521, -5.5916, -5.4333, -5.8017, -4.4669, -6.1402, -5.8595, -5.6929, -4.1846, -5.1547, -5.9296, -2.7617, -5.2379, -6.319, -3.7701, -5.1515, -4.1377, -5.2182, -5.9319, -4.0263, -4.6441, -5.3475, -4.1096, -4.654, -6.2115, -6.5359, -6.0991, -5.4564, -4.6336, -4.8042, -5.0037, -2.8489, -3.6784, -3.9251, -4.5236, -5.1485, -3.462, -4.8292, -4.5507, -4.8761, -4.3454, -4.4876, -4.5722, -4.7848, -4.3754, -4.5387, -4.8151, -4.9234, -4.955, -4.2333, -4.8224, -5.1493, -5.5557, -5.8116, -4.3479, -5.6212, -4.7493, -3.3583, -5.158, -4.3664, -5.8758, -4.0816, -5.2794, -6.0864, -5.6501, -5.7215, -6.3653, -3.4862, -5.8331, -5.4704, -4.1772, -5.7384, -4.7853, -3.2494, -5.4575, -5.4998, -6.2719, -5.0796, -4.8361, -5.4527, -3.5617, -3.8648, -4.2087, -3.993, -4.2725, -4.5099, -4.4799, -5.1564, -4.2873, -4.2189, -4.8227, -4.9252, -3.6843, -4.7837, -3.8392, -3.5441, -4.2335, -4.6646, -4.3357, -4.4342, -4.6591, -4.6481, -4.7388, -4.8066, -5.0394, -5.0656, -5.1954, -5.2118, -4.8229, -4.6613, -4.6243, -5.6025, -4.2312, -5.4125, -4.6054, -4.0269, -6.065, -5.253, -5.8397, -4.2968, -5.2646, -5.3445, -5.1496, -5.5637, -5.8956, -5.0113, -4.8164, -5.3672, -5.4827, -5.1292, -4.6153, -4.4019, -4.1482, -3.9643, -4.4482, -4.9524, -4.2658, -3.0749, -3.8149, -3.9564, -4.1011, -3.9476, -4.7107, -4.8666, -4.0009, -4.4022, -4.0548, -3.5925, -4.1662, -4.601, -4.4158, -4.3413, -4.1748, -3.9762, -4.4405, -4.7214, -4.6456, -4.5884], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7049, 0.7046, 0.7043, 0.7043, 0.7038, 0.7038, 0.7038, 0.7034, 0.7032, 0.7029, 0.7029, 0.7027, 0.7025, 0.7023, 0.702, 0.7017, 0.7016, 0.7014, 0.7008, 0.7007, 0.7006, 0.7006, 0.7003, 0.6993, 0.6986, 0.6983, 0.6983, 0.6978, 0.6978, 0.6978, 0.6909, 0.6736, 0.6894, 0.668, 0.6876, 0.676, 0.5842, 0.658, 0.6308, 0.4005, 0.4692, 0.5794, 0.4367, 0.3312, 0.5235, 0.0978, 2.4524, 2.4517, 2.447, 2.4298, 2.4261, 2.4183, 2.3984, 2.3756, 2.3594, 2.3518, 2.33, 2.3252, 2.3105, 2.2904, 2.2868, 2.2746, 2.2355, 2.2114, 2.1918, 2.1849, 2.1499, 2.1155, 2.1151, 2.0782, 2.0724, 2.0528, 2.039, 1.9812, 1.9723, 1.9447, 1.9311, 1.8741, 1.8336, 1.7063, 1.551, 1.5627, 1.5696, 1.5674, 1.7503, 0.9788, 0.935, 0.6988, 0.9713, -1.0359, 0.8726, -0.6843, 0.7293, 0.5035, 1.1571, 0.644, 0.8392, 0.0746, 2.4986, 2.4983, 2.4946, 2.4929, 2.4914, 2.4913, 2.4909, 2.4869, 2.4853, 2.4839, 2.4801, 2.4799, 2.4778, 2.4766, 2.4734, 2.4722, 2.4708, 2.4512, 2.4448, 2.4404, 2.437, 2.4341, 2.434, 2.4293, 2.4273, 2.4069, 2.4039, 2.3812, 2.3793, 2.3647, 2.3552, 2.3107, 2.3062, 2.3218, 2.1785, 2.1893, 2.0805, 2.297, 2.1692, 1.8148, 2.2268, 1.9529, 2.1902, 1.9014, 2.1664, 0.7536, 1.3722, 1.5923, 1.5858, 1.6942, 1.8152, 1.339, 0.5998, 0.9461, 1.563, -1.7812, 0.6975, 1.3412, 0.6988, 2.5912, 2.5908, 2.5904, 2.5873, 2.5867, 2.5864, 2.5858, 2.5838, 2.582, 2.5818, 2.5799, 2.5767, 2.5761, 2.5751, 2.5739, 2.5721, 2.5686, 2.5685, 2.5663, 2.5635, 2.563, 2.5629, 2.5616, 2.5532, 2.5482, 2.5482, 2.5462, 2.4992, 2.4804, 2.4465, 2.38, 2.1935, 2.0941, 1.8654, 1.9934, 1.7564, 2.0264, 1.9181, 2.1764, 0.0021, 1.4683, 1.203, 1.0148, -1.5413, 1.0867, -0.7098, 1.3505, -1.2426, 2.911, 2.9094, 2.8969, 2.8671, 2.8632, 2.8606, 2.8481, 2.8221, 2.8134, 2.8111, 2.7868, 2.7789, 2.7652, 2.7364, 2.6945, 2.6854, 2.6609, 2.6459, 2.626, 2.6145, 2.5929, 2.5368, 2.4854, 2.4617, 2.4297, 2.4247, 2.4017, 2.4016, 2.3996, 2.3887, 2.3174, 2.2938, 2.3394, 2.2247, 2.0948, 1.877, 2.048, 1.7651, 1.5457, 1.2507, 1.224, 1.0221, 1.2669, 1.6529, 2.0471, 1.1383, 1.6054, 1.4793, 0.9455, 0.8376, 0.3915, 2.9257, 2.9182, 2.9159, 2.9094, 2.9028, 2.8931, 2.8801, 2.8778, 2.8705, 2.8291, 2.829, 2.7979, 2.7544, 2.7466, 2.7292, 2.692, 2.6654, 2.6339, 2.6259, 2.612, 2.6108, 2.5888, 2.5874, 2.5723, 2.5553, 2.5521, 2.5354, 2.5221, 2.4761, 2.4251, 2.3787, 2.3984, 2.3642, 2.0167, 2.1488, 1.2061, 1.4483, 1.0094, 2.0424, 1.0223, 1.5475, 1.5686, 1.5638, 0.9344, 1.6028, 1.3112, 0.693, 1.1574, 1.6607, 2.945, 2.9428, 2.9399, 2.9354, 2.9295, 2.9253, 2.9234, 2.923, 2.917, 2.9163, 2.9053, 2.9007, 2.8938, 2.8929, 2.8813, 2.8301, 2.8043, 2.7965, 2.7885, 2.7838, 2.773, 2.769, 2.7577, 2.7265, 2.724, 2.7214, 2.7157, 2.7102, 2.6809, 2.6691, 2.6675, 2.5647, 2.5218, 2.646, 2.4088, 2.4077, 2.3477, 2.5503, 2.2548, 2.3883, 2.2758, 2.5441, 1.946, 1.7836, 2.3994, 1.9896, 1.5055, 2.2727, 1.3965, 0.986, 2.2226, 1.2238, 1.1316, 1.6169, 1.041, 1.3444, 3.2864, 3.254, 3.242, 3.2397, 3.2266, 3.225, 3.2249, 3.2038, 3.1931, 3.1843, 3.1797, 3.1505, 3.1495, 3.145, 3.1434, 3.136, 3.1197, 3.1096, 3.1095, 3.1059, 3.1002, 3.0685, 3.0572, 3.0566, 3.0433, 3.0302, 3.026, 2.9948, 2.9833, 2.9799, 2.975, 2.9764, 2.9359, 2.7425, 2.807, 2.8275, 2.8085, 2.9014, 2.3029, 2.7884, 2.4736, 2.475, 1.8881, 2.0341, 1.8869, 2.2439, 1.3127, -1.1291, 0.2183, 1.1513, 0.5781, 3.3526, 3.3408, 3.3189, 3.3096, 3.2964, 3.2956, 3.2839, 3.2619, 3.2539, 3.2044, 3.1983, 3.1505, 3.1479, 3.1266, 3.0584, 3.0579, 3.0361, 3.008, 2.9889, 2.9721, 2.9544, 2.9371, 2.9332, 2.8983, 2.8944, 2.8901, 2.8841, 2.8752, 2.8602, 2.8471, 2.839, 2.53, 2.5623, 2.4913, 2.3703, 2.4546, 2.4815, 2.4028, 2.7348, 2.2653, 2.1975, 2.5226, 2.5852, 1.705, 2.46, 1.4676, 0.6928, 1.5578, 2.1219, 1.3213, 1.4839, 1.5006, 1.0399, 1.4947, 3.372, 3.365, 3.3642, 3.3595, 3.3578, 3.3463, 3.3036, 3.3025, 3.2646, 3.2113, 3.1939, 3.1715, 3.1493, 3.1063, 3.0852, 3.0843, 3.069, 3.065, 3.0495, 3.0458, 3.0442, 3.0208, 3.0029, 2.9933, 2.9907, 2.9618, 2.9596, 2.9326, 2.9126, 2.9117, 2.885, 2.8163, 2.8711, 2.6464, 2.3084, 2.5018, 2.459, 2.4721, 2.2144, 2.6659, 2.7787, 2.0908, 2.3823, 2.0082, 1.441, 1.9143, 2.4305, 2.0046, 1.8025, 1.1205, 0.2607, 1.6342, 2.2701, 1.1456, 0.2271]}, \"token.table\": {\"Topic\": [1, 2, 3, 5, 6, 8, 10, 5, 6, 10, 1, 3, 5, 6, 7, 8, 10, 2, 6, 2, 5, 7, 9, 10, 3, 4, 10, 1, 5, 9, 2, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 5, 8, 1, 2, 3, 4, 5, 7, 8, 9, 7, 8, 7, 9, 10, 2, 2, 5, 6, 8, 9, 10, 2, 9, 2, 3, 4, 5, 6, 7, 9, 2, 8, 9, 2, 5, 1, 3, 4, 1, 1, 8, 10, 5, 6, 9, 10, 2, 5, 6, 8, 9, 2, 3, 5, 6, 9, 4, 7, 1, 2, 7, 8, 9, 7, 4, 6, 10, 6, 3, 6, 8, 10, 5, 2, 5, 6, 9, 10, 2, 3, 5, 6, 7, 9, 10, 3, 2, 5, 7, 3, 5, 9, 10, 2, 5, 6, 8, 9, 5, 6, 6, 2, 5, 7, 5, 7, 1, 3, 4, 8, 7, 1, 2, 3, 5, 6, 7, 8, 10, 6, 7, 6, 7, 8, 1, 1, 2, 5, 7, 8, 9, 10, 3, 2, 3, 5, 6, 7, 7, 3, 7, 6, 3, 4, 8, 5, 6, 7, 8, 7, 9, 6, 8, 9, 10, 3, 7, 4, 7, 8, 2, 3, 8, 9, 10, 2, 5, 6, 2, 10, 1, 2, 6, 2, 3, 7, 2, 3, 5, 6, 7, 8, 10, 2, 8, 9, 7, 2, 7, 7, 2, 6, 1, 2, 5, 6, 9, 10, 2, 5, 6, 7, 9, 10, 9, 2, 3, 9, 2, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 7, 8, 10, 5, 6, 5, 10, 1, 4, 7, 6, 2, 5, 7, 10, 1, 2, 5, 6, 7, 8, 10, 7, 1, 2, 6, 7, 2, 8, 3, 8, 10, 3, 2, 6, 7, 9, 2, 6, 7, 10, 2, 8, 6, 9, 6, 9, 2, 3, 5, 6, 9, 2, 5, 6, 8, 9, 2, 5, 6, 7, 8, 9, 10, 2, 5, 8, 2, 3, 9, 2, 5, 7, 9, 10, 8, 7, 1, 3, 4, 1, 4, 2, 3, 5, 6, 8, 9, 10, 2, 3, 4, 5, 7, 9, 3, 8, 2, 9, 10, 5, 7, 8, 9, 10, 6, 7, 8, 1, 2, 6, 7, 8, 9, 10, 6, 8, 7, 8, 7, 9, 10, 1, 1, 1, 7, 8, 2, 4, 5, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 3, 7, 8, 1, 2, 5, 6, 8, 9, 2, 7, 3, 6, 9, 3, 2, 7, 9, 1, 3, 9, 4, 4, 5, 9, 10, 5, 9, 2, 4, 6, 7, 9, 6, 8, 3, 5, 6, 7, 8, 9, 10, 3, 4, 2, 6, 2, 5, 8, 2, 5, 6, 7, 8, 9, 10, 1, 9, 7, 2, 3, 6, 8, 9, 10, 1, 2, 7, 3, 4, 5, 1, 1, 8, 6, 2, 5, 3, 4, 4, 3, 1, 3, 4, 7, 10, 1, 3, 4, 1, 3, 4, 7, 8, 1, 2, 7, 2, 4, 7, 9, 2, 6, 8, 2, 8, 7, 5, 1, 1, 7, 8, 1, 1, 4, 8, 1, 1, 7, 8, 2, 3, 5, 6, 7, 8, 9, 10, 10, 5, 8, 10, 1, 6, 9, 10, 6, 8, 9, 3, 5, 7, 9, 10, 2, 3, 6, 7, 2, 3, 7, 8, 9, 10, 5, 6, 2, 6, 7, 8, 10, 8, 10, 2, 3, 5, 6, 7, 8, 9, 10, 4, 1, 4, 1, 10, 2, 9, 1, 3, 9, 6, 8, 10, 1, 5, 2, 5, 6, 10, 1, 3, 4, 7, 1, 1, 2, 5, 6, 7, 9, 10, 3, 5, 6, 7, 8, 9, 1, 4, 5, 2, 5, 6, 7, 5, 6, 9, 2, 5, 6, 7, 9, 4, 3, 7, 4, 5, 8, 5, 7, 10, 4, 4, 3, 7, 10, 10, 3, 6, 1, 2, 3, 5, 8, 9, 6, 7, 1, 6, 10, 3, 9, 4, 5, 6, 7, 9, 10, 1, 6, 10, 8, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 4, 4, 10, 1, 2, 3, 4, 7, 10, 8, 9, 1, 6, 8, 10, 4, 2, 3, 5, 6, 7, 8, 10, 3, 4, 6, 7, 8, 9, 10, 1, 7, 8, 1, 3, 5, 7, 8, 1, 4, 3, 1, 2, 3, 4, 5, 6, 8, 9, 4, 4, 2, 3, 5, 7, 8, 6, 7, 8, 2, 6, 7, 4, 5, 7, 8, 4, 4, 1, 2, 3, 5, 1, 4, 5, 6, 1, 2, 4, 8, 2, 5, 6, 9, 10, 2, 3, 5, 6, 7, 9, 5, 9, 7, 9, 2, 2, 3, 4, 5, 8, 5, 3, 1, 4, 7, 3, 2, 6, 6, 5, 6, 7, 9, 2, 6, 7, 10, 4, 6, 7, 9, 2, 5, 5, 7, 8, 2, 3, 5, 8, 9, 10, 4, 8, 9, 3, 4, 6, 7, 3, 5, 6, 10, 2, 7, 8, 9, 10, 1, 3, 4, 8, 9, 10, 8, 9, 2, 9, 3, 4, 6, 9, 10, 1, 8, 9, 6, 7, 8, 9, 1, 5, 2, 6, 7, 9, 2, 3, 6, 7, 8, 1, 3, 4, 9, 3, 9, 5, 2, 10, 1, 2, 3, 4, 7, 2, 9, 3, 6, 2, 8, 2, 10, 1, 1, 8, 5, 6, 7, 9, 2, 5, 7, 9, 10, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 3, 9, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 8, 9, 2, 3, 4, 7, 2, 9, 2, 5, 6, 8, 9, 5, 6, 1, 2, 5, 6, 7, 8, 10, 6, 2, 4, 6, 1, 3, 5, 2, 7, 9, 2, 4, 5, 6, 8, 9, 2, 3, 5, 6, 7, 9, 6, 8, 1, 8, 1, 2, 9, 2, 3, 2, 5, 9, 10, 7, 9, 10, 9, 10, 7, 8, 9, 2, 5, 6, 8, 9, 5, 3, 5, 1, 3, 9, 10, 1, 2, 5, 7, 8, 9, 2, 6, 8, 2, 3, 4, 5, 6, 8, 9, 5, 6, 10, 1, 2, 5, 6, 8, 9, 10, 7, 10, 2, 3, 6, 8, 1, 2, 3, 4, 6, 7, 2, 3, 7, 9, 10, 9, 2, 3, 5, 6, 8, 10, 4, 9, 10, 4, 4, 5, 6, 8, 5, 7, 6, 10, 4, 7, 3, 6, 8, 10, 3, 7, 8, 7, 8, 2, 3, 3, 4, 1, 3, 4, 8, 10, 1, 3, 4, 1, 3, 10, 1, 2, 4, 6, 10, 1, 2, 3, 5, 7, 6, 8, 6, 8, 8, 1, 2, 3, 7, 8, 10, 6, 8, 2, 5, 6, 8, 10, 6, 9, 3, 4, 1, 7, 3, 2, 3, 6, 8, 10, 1, 3, 4, 8, 1, 3, 2, 6, 6, 8, 3, 10, 2, 6, 8, 7, 1, 1, 2, 6, 9, 1, 3, 4, 8, 9, 3, 4, 6, 9, 1, 2, 3, 6, 7, 8, 9, 6, 10, 3, 4, 6, 4, 7, 6, 3, 8, 1, 8, 2, 3, 6, 9, 10, 1, 2, 3, 5, 6, 8, 10, 8, 5, 8, 9, 1, 3, 6, 7, 8, 2, 5, 6, 7, 9, 10, 2, 5, 6, 7, 2, 7, 8, 4, 8, 9, 5, 8, 2, 3, 6, 9, 2, 6, 5, 6, 9, 1, 3, 4, 3, 4, 5, 6, 7, 10, 2, 1], \"Freq\": [0.2011664524528633, 0.026239102493851738, 0.2930033111813444, 0.07434412373257993, 0.13994187996720925, 0.013119551246925869, 0.2492714736915915, 0.041502805151648496, 0.8359850751974912, 0.11857944329042429, 0.04035110013679632, 0.5465739927620592, 0.12105330041038895, 0.08803876393482833, 0.16874096420842097, 0.022009690983707083, 0.011004845491853541, 0.8353616208762912, 0.11522229253466085, 0.10405091304734318, 0.28614001088019375, 0.0650318206545895, 0.4552227445821264, 0.0650318206545895, 0.2679505632877503, 0.1786337088585002, 0.5359011265755006, 0.9975867695757246, 0.6366608105899769, 0.31833040529498846, 0.5884234724404871, 0.2533079269969936, 0.1360174860917709, 0.004928169785933728, 0.00689943770030722, 0.009856339571867457, 0.14517441799707287, 0.01935658906627638, 0.31938371959356027, 0.004839147266569095, 0.2080833324624711, 0.00967829453313819, 0.2855096887275766, 0.11913961049107544, 0.8339772734375281, 0.7370034624827823, 0.0430744279650954, 0.1731592004196835, 0.0215372139825477, 0.001292232838952862, 0.0068919084744152636, 0.012060839830226712, 0.004953559215985971, 0.1907534398257495, 0.7948059992739562, 0.20097826527782212, 0.5874749292736339, 0.18551839871798964, 0.9458656464403808, 0.4099091983922847, 0.14377412182415955, 0.07953462058357763, 0.07035754897778021, 0.04588535802898709, 0.2477809333565303, 0.9897863869971235, 0.006385718625787893, 0.01079257277122458, 0.5756038811319776, 0.2878019405659888, 0.0359752425707486, 0.028780194056598877, 0.0035975242570748596, 0.057560388113197754, 0.847188795872783, 0.07701716326116209, 0.9579494987308056, 0.38843934134651087, 0.5965318456392846, 0.6105974436731825, 0.0623968190614931, 0.325354842249214, 0.9926972072648974, 0.9980093912244922, 0.265307413835314, 0.6897992759718165, 0.9015775467949491, 0.02385125785171823, 0.05724301884412375, 0.014310754711030937, 0.21736961843823266, 0.7469016212501679, 0.021246654433812216, 0.0016343580333701704, 0.011440506233591193, 0.011224573104362584, 0.1964300293263452, 0.499493503144135, 0.12347030414798843, 0.16836859656543876, 0.054138168769187145, 0.8662107003069943, 0.9926565576398447, 0.7576503264612949, 0.21735870021430592, 0.0062102485775515975, 0.012420497155103195, 0.9825750762774854, 0.9912549620278726, 0.7388734556249795, 0.2522982531402369, 0.9940492316939251, 0.017789048234925546, 0.12452333764447882, 0.2668357235238832, 0.587038591752543, 0.8976808167222675, 0.1075076832737952, 0.13579917887216236, 0.6620209970017915, 0.005658299119673432, 0.07921618767542804, 0.40797412052036436, 0.20630509503586608, 0.03708855641094221, 0.0788131823732522, 0.17617064295197551, 0.053314799840729434, 0.0394065911866261, 0.9574233804901797, 0.7771517725721844, 0.11102168179602634, 0.08326626134701975, 0.8612241007194245, 0.05450785447591294, 0.05450785447591294, 0.021803141790365178, 0.09200739360807668, 0.13879081408675972, 0.5754360718878015, 0.001559447349289435, 0.1902525766133111, 0.20235303178863062, 0.7644447867570491, 0.9790811009038665, 0.6596098150170514, 0.13192196300341028, 0.17589595067121372, 0.7237808683466842, 0.18094521708667105, 0.180391488319832, 0.721565953279328, 0.07278954791852871, 0.02531810362383607, 0.9644980963038616, 0.004258648519441785, 0.06671882680458797, 0.16324819324526843, 0.07949477236291333, 0.22712792103689522, 0.3108813419192503, 0.04542558420737904, 0.10220756446660285, 0.11640990124302546, 0.85367260911552, 0.6299173548426573, 0.11453042815321042, 0.22906085630642084, 0.9978172397693644, 0.03328213809972049, 0.9046690265287661, 0.006051297836312817, 0.015128244590782044, 0.0030256489181564087, 0.027230840263407677, 0.012102595672625635, 0.9883019546061532, 0.012543534548350294, 0.31045248007166976, 0.11289181093515264, 0.06585355637883904, 0.49546961465983663, 0.9639484461417033, 0.9405535237385207, 0.05788021684544743, 0.9827847662475704, 0.3053121928761044, 0.3294157870505337, 0.353519381224963, 0.30990870668849535, 0.060634312178183866, 0.5659202469963828, 0.060634312178183866, 0.36052578964066545, 0.6309201318711645, 0.1879353932017007, 0.7517415728068028, 0.2517757485059137, 0.6923833083912627, 0.992854015434415, 0.005144321323494378, 0.12017598228210541, 0.0772559886099249, 0.7983118823025573, 0.05689131684759934, 0.05689131684759934, 0.22756526739039737, 0.15929568717327816, 0.4778870615198345, 0.07370749896079405, 0.09213437370099256, 0.8107824885687346, 0.05050889745044435, 0.858651256657554, 0.23623243719612472, 0.1528562828916101, 0.5975291058490213, 0.7919591528114766, 0.11732728189799653, 0.07332955118624783, 0.17710907033082743, 0.12942585908791235, 0.04768321124291508, 0.01589440374763836, 0.21116850693290964, 0.3701125444092932, 0.04995384034972056, 0.1713209671635733, 0.2855349452726222, 0.5329985645088947, 0.9503832629399864, 0.6069247207512807, 0.3468141261435889, 0.9899913651272148, 0.1327401434736953, 0.7964408608421718, 0.12085549646050159, 0.07251329787630095, 0.2658820922131035, 0.12085549646050159, 0.03222813238946709, 0.3786805555762383, 0.16447943634372875, 0.1859332758668238, 0.08581535809238021, 0.07866407825134852, 0.007151279841031684, 0.4719844695080912, 0.9819157083289012, 0.6943835116046551, 0.030190587461071956, 0.2717152871496476, 0.1715384118335235, 0.5484858773275719, 0.03168543912848523, 0.03933364857329201, 0.04588925666884068, 0.02185202698516223, 0.1409455740542964, 0.7635554253241279, 0.010805029603643318, 0.012605867870917206, 0.012605867870917206, 0.04322011841457327, 0.003601676534547773, 0.06122850108731214, 0.0666310158891338, 0.025211735741834412, 0.021893520270803962, 0.10321230984807582, 0.025021166023775954, 0.6474226708652029, 0.06255291505943988, 0.13761641313076775, 0.8606622488550861, 0.12750551834890164, 0.21416807816667452, 0.7821790680869851, 0.10447492271406594, 0.8940068386532214, 0.9647945211423293, 0.9488332294828354, 0.030357001326156312, 0.2124990092830942, 0.060714002652312624, 0.6678540291754389, 0.15989586559769986, 0.1346491499770104, 0.0504934312413789, 0.28192165776436556, 0.26088272808045765, 0.0504934312413789, 0.054701217178160476, 0.9861782082691446, 0.12531989554159348, 0.06265994777079674, 0.6982108465888779, 0.10741705332136584, 0.04105558362203792, 0.9442784233068722, 0.9293896514386218, 0.7846662492615125, 0.19616656231537813, 0.9827844863217914, 0.030616916074438023, 0.16839303840940914, 0.6582636956004175, 0.1377761223349711, 0.47004409081772575, 0.26459435575832246, 0.03424162250990055, 0.22723985847479458, 0.12429088812170334, 0.8700362168519234, 0.21539568086287836, 0.7323453149337864, 0.3693468335188798, 0.5966371926074212, 0.22690785069019762, 0.051700522942070344, 0.1680266995617286, 0.40067905280104515, 0.1493570662770921, 0.11454713080073226, 0.027273126381126726, 0.6872827848043935, 0.07091012859092949, 0.09818325497205621, 0.11328839265082681, 0.2076953865265158, 0.1069945930591142, 0.018881398775137802, 0.1007007934674016, 0.0818193946922638, 0.3587465767276182, 0.2171867823149615, 0.15927030703097175, 0.6081229904818921, 0.13926312284874173, 0.8102581693017701, 0.025320567790680315, 0.029949710350910826, 0.039932947134547765, 0.5790277334509426, 0.33443843225183756, 0.014974855175455413, 0.9646004223774144, 0.9433059433298666, 0.05207775247487275, 0.833244039597964, 0.11457105544472004, 0.9916933164703512, 0.0055817635073378115, 0.2039393477037266, 0.04204935004200549, 0.31537012531504116, 0.19763194519742577, 0.1387628551386181, 0.09671350509661261, 0.004204935004200549, 0.4094459429846737, 0.017423231616369092, 0.1655207003555064, 0.07404873436956864, 0.021779039520461365, 0.3092623611905514, 0.11518321197323372, 0.863874089799253, 0.03185341743832212, 0.7963354359580529, 0.1592670871916106, 0.10072785203680154, 0.06043671122208092, 0.03357595067893385, 0.20145570407360308, 0.5976519220850225, 0.044958391543163535, 0.05619798942895442, 0.8879282329774798, 0.01864870132229482, 0.06760154229331872, 0.2517574678509801, 0.36598076345003583, 0.03030413964872908, 0.16317613657007968, 0.10489894493790837, 0.15995207248471097, 0.8297513760144382, 0.25827690367874184, 0.7317845604231018, 0.017545694164369803, 0.29827680079428665, 0.6667363782460525, 0.9958988637523984, 0.9990212602547968, 0.022157134659491002, 0.7865782804119306, 0.18279636094080076, 0.2567175207674217, 0.06417938019185543, 0.5776144217266989, 0.10832747522318653, 0.18570424323974832, 0.11761268738517394, 0.04952113153059955, 0.09594719234053664, 0.05880634369258697, 0.11761268738517394, 0.09594719234053664, 0.17022888963643598, 0.8997859833617222, 0.11510851509805899, 0.5018731258275372, 0.3821602701255558, 0.8951452182348923, 0.12260640146676352, 0.5339831432302464, 0.1839096022001453, 0.14841827545976638, 0.0024198631868440168, 0.008872831685094729, 0.14408006584600752, 0.8164537064607092, 0.8221713673552536, 0.09642750604783838, 0.08120211035607443, 0.987713876842828, 0.05004756371047334, 0.8007610193675735, 0.10009512742094669, 0.013732483408489466, 0.12359235067640519, 0.8376814879178573, 0.964937484716692, 0.9496537144231649, 0.7675094350726355, 0.07195400953805958, 0.1199233492300993, 0.8746874971669166, 0.09718749968521295, 0.05738634353100719, 0.08416663717881054, 0.05738634353100719, 0.6771588536658848, 0.12242419953281534, 0.7142351258809488, 0.22554793448872068, 0.092864951027323, 0.0033166053938329643, 0.03979926472599558, 0.01989963236299779, 0.013266421575331857, 0.6235218140405974, 0.20231292902381084, 0.1759424701139133, 0.8093353625240013, 0.6638692507623186, 0.31446438194004567, 0.7345518638747959, 0.025329374616372274, 0.2026349969309782, 0.5561695866156224, 0.15024953402813537, 0.1783289551415902, 0.0014778642691292004, 0.0014778642691292004, 0.06896699922602935, 0.04335068522778988, 0.11845529342164703, 0.8291870539515291, 0.974894985424953, 0.20894288237583625, 0.18528897116347742, 0.09461564484943528, 0.09461564484943528, 0.007884637070786273, 0.4060588091454931, 0.09693516486416447, 0.03231172162138816, 0.8401047621560921, 0.4997765971790036, 0.4831727235185716, 0.014943486294388813, 0.9981504996927087, 0.14673006467577865, 0.8216883621843605, 0.97229216330352, 0.8585847189037309, 0.0715487265753109, 0.9050255459808904, 0.04525127729904452, 0.9812652218611102, 0.9793354011655687, 0.6874390243234706, 0.03965994371096946, 0.034702450747098275, 0.2346546669565693, 0.0016524976546237276, 0.1866333893810704, 0.7126002140004506, 0.0933166946905352, 0.968371597945336, 0.013740855247799673, 0.016003405710288778, 5.518415762168544e-05, 0.001765893043893934, 0.9957519139987071, 0.139771456703301, 0.8386287402198058, 0.4881398682393996, 0.009962038127334686, 0.08965834314601216, 0.40844356322072206, 0.270665968675013, 0.10733305654353965, 0.6159984114672711, 0.8998372385433611, 0.09998191539370678, 0.9154347298065911, 0.926230084499282, 0.9954082392058922, 0.046163545348771096, 0.8441334006632429, 0.10551667508290537, 0.9985681830027581, 0.9526529795465563, 0.020785155917379408, 0.02598144489672426, 0.9981903310279322, 0.9836925876016387, 0.007368483802259466, 0.008289544277541899, 0.19880315802225537, 0.057282265870819346, 0.2830417843028721, 0.1549990723563347, 0.06065181092204401, 0.020217270307348004, 0.1549990723563347, 0.07412999112694268, 0.9611260856138455, 0.09004337093196678, 0.1913421632304294, 0.7203469674557342, 0.04786306340990282, 0.45687469618543597, 0.10442850198524252, 0.3916068824446594, 0.989123342239303, 0.3341554280525485, 0.6014797704945873, 0.09542962918297321, 0.04337710417407874, 0.5031744084193133, 0.23423636254002517, 0.1127804708526047, 0.05440302615573213, 0.013600756538933032, 0.13600756538933031, 0.7888438792581158, 0.0653711761778767, 0.3506272176813387, 0.05942834197988791, 0.07725684457385429, 0.4041127254632378, 0.04159983938592154, 0.7882091231827307, 0.17134980938755018, 0.37597633464952795, 0.1279919437104776, 0.0159989929638097, 0.43997230650476676, 0.03999748240952425, 0.07890424591919114, 0.907398828070698, 0.10001084971618232, 0.059097320286835, 0.11819464057367, 0.09091895428743847, 0.17274601314613308, 0.24548117657608387, 0.11819464057367, 0.09546490200181039, 0.9886864847928272, 0.9630847613558872, 0.036840892979577614, 0.025135671603252908, 0.9551555209236106, 0.0524635315410226, 0.9443435677384068, 0.13581993533354866, 0.13581993533354866, 0.7243729884455928, 0.11804157945763422, 0.14755197432204276, 0.7082494767458053, 0.9951692319690666, 0.00443988822420871, 0.9833735807123675, 0.15280627717140177, 0.03395695048253373, 0.7979883363395427, 0.9283165896197876, 0.013024850109461306, 0.013024850109461306, 0.04499493674177542, 0.9951881706924851, 0.9906991238783296, 0.047636290005293284, 0.43931245227103805, 0.25406021336156415, 0.05292921111699254, 0.15084825168342872, 0.05292921111699254, 0.9752201091876462, 0.1091763385712335, 0.01819605642853892, 0.045490141071347294, 0.7824304264271734, 0.03639211285707784, 0.9713584063003309, 0.027654331851966717, 0.9835218302764446, 0.11187210268163321, 0.6320773801512277, 0.03915523593857163, 0.21255699509510312, 0.4164291004351347, 0.16194465016921905, 0.4164291004351347, 0.05892554774503833, 0.06874647236921139, 0.03928369849669222, 0.009820924624173055, 0.8053158191821905, 0.998727768334856, 0.9900103599929436, 0.9365867289811437, 0.966239471611011, 0.060810024460696714, 0.9121503669104507, 0.9481604470569704, 0.0224682570392647, 0.0224682570392647, 0.9990152527447723, 0.9934729141880575, 0.7548577363955883, 0.19864677273568113, 0.03972935454713623, 0.9785694186894076, 0.9259370346416831, 0.07122592574166793, 0.22704708324019957, 0.03784118054003326, 0.37210494197699373, 0.03784118054003326, 0.03153431711669438, 0.29011571747358833, 0.9050148000730837, 0.08922681127481107, 0.9982444393074826, 0.8369670390833194, 0.14348006384285475, 0.9265854318581876, 0.048767654308325664, 0.98748490323235, 0.5350148453449071, 0.10827681393885025, 0.20063056700434018, 0.019107673048032396, 0.13693832351089885, 0.9954082355341728, 0.2138612029901842, 0.7485142104656448, 0.23813239203237713, 0.7441637251011786, 0.19460458918213677, 0.07241100992823694, 0.3100096362552644, 0.07919954210900915, 0.16971330451930533, 0.1040908267718406, 0.013577064361544426, 0.045256881205148085, 0.011314220301287021, 0.9833430177969833, 0.9573556783485724, 0.9641490795822302, 0.7890391784324298, 0.008786627822187414, 0.1484940101949673, 0.0035146511288749655, 0.007029302257749931, 0.04217581354649959, 0.8266980890656996, 0.13778301484428326, 0.11930250545624115, 0.06817286026070922, 0.7328582478026242, 0.06817286026070922, 0.9939764780286469, 0.40199697108081334, 0.3213672061075843, 0.0529852741252648, 0.051833420339932955, 0.13937430802515305, 0.00345556135599553, 0.028796344633296084, 0.9305765298523306, 0.06263495874006071, 0.10019394530618485, 0.5788983506579569, 0.044530642358304375, 0.2115205512019458, 0.06679596353745657, 0.49914508344349007, 0.05546056482705445, 0.4436845186164356, 0.03310549670769348, 0.867364013741569, 0.006621099341538695, 0.03972659604923217, 0.04634769539077087, 0.9969421946473345, 0.9924570698806863, 0.9786014344513961, 0.8855701187805145, 0.030299119212641484, 0.004544867881896223, 0.0750164399816434, 0.002820952478418345, 0.0012015167963633693, 5.2239860711450835e-05, 0.0005223986071145084, 0.9496527776810337, 0.9597211150334262, 0.06218062299464, 0.12436124598928, 0.55962560695176, 0.08290749732618667, 0.16581499465237334, 0.6851869573874653, 0.22065342695528542, 0.08129336782563147, 0.05880913048351085, 0.25876017412744773, 0.6704240875120236, 0.07871528539847927, 0.015743057079695855, 0.09445834247817513, 0.7871528539847927, 0.9929670019893267, 0.9866065823246409, 0.15082832454040337, 0.10893156772362467, 0.016758702726711486, 0.7206242172485939, 0.9829198227060817, 0.016946893494932443, 0.6827866995606131, 0.28114746452495837, 0.9943089205100862, 0.07045131326872549, 0.859506021878451, 0.0422707879612353, 0.1259177717085782, 0.14795338175757938, 0.022035610049001186, 0.43126836810188035, 0.2707232091734431, 0.03018453575662506, 0.0965905144212002, 0.1026274215725252, 0.4105096862901008, 0.13281195732915027, 0.21732865744770044, 0.7924613992628401, 0.1698131569848943, 0.786864455715497, 0.16861381193903507, 0.9749955002876008, 0.009286027414085329, 0.2321506853521332, 0.6593079464000583, 0.037144109656341316, 0.05571616448451197, 0.9069007214585794, 0.9903671620159009, 0.9914303472403833, 0.08814226800019623, 0.793280412001766, 0.9775257111944632, 0.086456085151655, 0.9077888940923774, 0.9806976347655861, 0.1869311377996187, 0.12462075853307915, 0.031155189633269787, 0.6231037926653957, 0.9174012076314428, 0.2970890716738125, 0.06752024356223012, 0.621186240772517, 0.9984138873006754, 0.1676037403668424, 0.0838018701834212, 0.6704149614673696, 0.0365398854193791, 0.9500370209038568, 0.09285585316696554, 0.12380780422262072, 0.7737987763913795, 0.054729446998832594, 0.10945889399766519, 0.42219859113385144, 0.10945889399766519, 0.10164040156926053, 0.20328080313852107, 0.9763390590257474, 0.08584914524139049, 0.9014160250346003, 0.004415494050492352, 0.9934861613607792, 0.11359641251912574, 0.8709058293132973, 0.03213502649049861, 0.23565686093032315, 0.7105411412899137, 0.01785279249472145, 0.3541051560498982, 0.04860266847743701, 0.11109181366271316, 0.3818781094655765, 0.10414857530879358, 0.02480172386870548, 0.16431142063017382, 0.4340301677023459, 0.034102370319470034, 0.00620043096717637, 0.3363733799693181, 0.7315323772047996, 0.14630647544095993, 0.12196744718359186, 0.853772130285143, 0.1987124781532523, 0.17323651941565585, 0.21909324514332945, 0.015285575242557869, 0.3974249563065046, 0.994697716612389, 0.6993273303352854, 0.27973093213411415, 0.7439678548748698, 0.24798928495828992, 0.2848636071249275, 0.6646817499581641, 0.08631427759378485, 0.8919142018024435, 0.09127240621249544, 0.5818615896046584, 0.06845430465937158, 0.23959006630780053, 0.07513918222088241, 0.2160251488850369, 0.1033163755537133, 0.47901228665812534, 0.1127087733313236, 0.5437693535907585, 0.21064938922885237, 0.20575056622353022, 0.03755764304080313, 0.8855101462715255, 0.09839001625239172, 0.9914988658596221, 0.20541573765115412, 0.7531910380542317, 0.05113081516640308, 0.05113081516640308, 0.13066763875858567, 0.5681201685155898, 0.19884205898045643, 0.37969362568918413, 0.5995162510881854, 0.4191765513240135, 0.5654009296928554, 0.7608544079955991, 0.19021360199889978, 0.833707126591837, 0.1471247870456183, 0.9983899378732639, 0.06243337794792328, 0.8740672912709259, 0.5858262404939114, 0.16272951124830873, 0.032545902249661744, 0.19527541349797048, 0.08515213401387416, 0.007741103092170378, 0.16256316493557793, 0.41027846388503003, 0.32512632987115586, 0.02537049343842929, 0.09640787506603131, 0.12685246719214646, 0.03551869081380101, 0.04059278950148686, 0.5074098687685858, 0.010148197375371716, 0.15222296063057575, 0.1984999577355563, 0.28672216117358135, 0.07719442800827189, 0.430083241760372, 0.059437918483264664, 0.9361472161114185, 0.07092828682737527, 0.18576456073836378, 0.04728552455158351, 0.11483627391098852, 0.006755074935940502, 0.1790094858024233, 0.08781597416722652, 0.003377537467970251, 0.3073559095852928, 0.2612122691231487, 0.6203791391674782, 0.10883844546797863, 0.1575670569872289, 0.14148878586608307, 0.11897920629647896, 0.578817760361249, 0.20004135045850163, 0.7334849516811726, 0.6784810692943022, 0.1919250731184188, 0.10685558124971425, 0.0010374328276671287, 0.0217860893810097, 0.8288355249981338, 0.15977552289120653, 0.09790331567404453, 0.1646555763608931, 0.00445015071245657, 0.10680361709895768, 0.5473685376321581, 0.05340180854947884, 0.02225075356228285, 0.9707814795407973, 0.8797905325288482, 0.05386472648135805, 0.0718196353084774, 0.01852859846100302, 0.9727514192026586, 0.004632149615250755, 0.09310346878582935, 0.7564656838848636, 0.1512931367769727, 0.6131648674244055, 0.02270980990460761, 0.18887915067002914, 0.14622901987357095, 0.008862364840822482, 0.01938642308929918, 0.13534551701071212, 0.6541699988851086, 0.08378532005425036, 0.00322251230977886, 0.08700783236402922, 0.035447635407567464, 0.29001150467815173, 0.6692573184880425, 0.051019360120590364, 0.9183484821706266, 0.9995724861583821, 0.9920619051467754, 0.006673062142242884, 0.8707187857251845, 0.09165460902370362, 0.891671445837181, 0.055729465364823816, 0.155671184441974, 0.8172737183203636, 0.025805069754989717, 0.2580506975498972, 0.6967368833847224, 0.06147177132509031, 0.9015859794346579, 0.26293071668788537, 0.09279907647807718, 0.6186605098538479, 0.041651963064630836, 0.7606010646584762, 0.07606010646584761, 0.05251769255975192, 0.06700533188658005, 0.9914256602920848, 0.7264928326039192, 0.26010237216683524, 0.21007184426981837, 0.08752993511242431, 0.6477215198319399, 0.043764967556212155, 0.007256007843506055, 0.17777219216589835, 0.268472290209724, 0.1414921529483681, 0.2467042666792059, 0.15237616471362717, 0.0366283393822629, 0.09941977832328501, 0.8607659754831781, 0.12471836844107918, 0.08776477779187054, 0.04157278948035973, 0.004619198831151081, 0.023095994155755403, 0.03233439181805756, 0.68364142701036, 0.06076717768441393, 0.10938091983194506, 0.8264336165080294, 0.0452335972840315, 0.16334354574789153, 0.35181686776468946, 0.2563237179428452, 0.08544123931428173, 0.015077865761343833, 0.08292826168739109, 0.9703882104237174, 0.01590800344956914, 0.12104488392036163, 0.7128198719754629, 0.10087073660030135, 0.053797726186827384, 0.47355875956747767, 0.033825625683391265, 0.19618862896366934, 0.22099408779815627, 0.033825625683391265, 0.040590750820069514, 0.004649013801090977, 0.7298951667712834, 0.004649013801090977, 0.08833126222072857, 0.17201351064036616, 0.9490332299150146, 0.05663876164194229, 0.0021784139093054726, 0.12416959283041194, 0.710162934433584, 0.030497794730276615, 0.07624448682569154, 0.9727833832968459, 0.27284705396040715, 0.7016067101839041, 0.9538711529383855, 0.9857505895609513, 0.6202502314752859, 0.27291010184912584, 0.07443002777703431, 0.6638917314324089, 0.33194586571620444, 0.3247348771811862, 0.6494697543623724, 0.17665517607749795, 0.777282774740991, 0.02152681988508752, 0.15068773919561265, 0.15068773919561265, 0.6673314164377132, 0.8183527281062817, 0.07482082085543147, 0.10287862867621828, 0.7810082441300351, 0.17355738758445224, 0.03225937548108342, 0.9355218889514192, 0.9466576151159699, 0.992060606087751, 0.9982578115896977, 0.11189001206810817, 0.02097937726277028, 0.8391750905108113, 0.027972503017027042, 0.9853956975774527, 0.001462879598541349, 0.013165916386872142, 0.09083692210524828, 0.8982762297074554, 0.9539769465868936, 0.8822021170852714, 0.030123974729740974, 0.015061987364870487, 0.006455137442087352, 0.06455137442087351, 0.04198960573963852, 0.017289837657498214, 0.9336512335049036, 0.004939953616428062, 0.002469976808214031, 0.22981748117637382, 0.7222835122686034, 0.09093222748865178, 0.818390047397866, 0.9480144788290608, 0.17889674057399355, 0.2251994263696154, 0.39778216433511504, 0.1620594002846765, 0.01262800521698778, 0.023151342897810928, 0.046783235140976445, 0.9356647028195288, 0.22061968817970348, 0.5929154119829532, 0.013788730511231468, 0.027577461022462935, 0.13788730511231467, 0.29210177174951224, 0.6491150483322493, 0.9790419354948617, 0.9915729293694768, 0.9963431016510228, 0.9524272514717895, 0.961943907905811, 0.03207872654426014, 0.1710865415693874, 0.04277163539234685, 0.12831490617704056, 0.6201887131890294, 0.0038173158551678757, 0.16987055555497046, 0.25003418851349585, 0.5764146941303492, 0.9906991288636715, 0.9865597814412022, 0.24560018791280708, 0.7368005637384212, 0.0033092412592722674, 0.9927723777816801, 0.9867876340978715, 0.9753406190995588, 0.1987055240343395, 0.6844301383405027, 0.11039195779685529, 0.9839433653875098, 0.9979695044524, 0.06156660924346743, 0.7080160062998754, 0.12313321848693486, 0.09234991386520114, 0.8322611399657884, 0.06341037256882198, 0.05284197714068498, 0.034347285141445236, 0.013210494285171246, 0.036818355525183644, 0.9081861029545298, 0.036818355525183644, 0.9744358827180933, 0.034650139946640804, 0.1406388033128362, 0.4015339746757787, 0.11821812452383333, 0.14675353389165519, 0.02649716584154885, 0.12840934215519828, 0.3310014560165706, 0.6620029120331412, 0.2686693021465756, 0.6690392426002961, 0.05794828085514376, 0.9770036351025517, 0.9603147266482748, 0.9293952119312034, 0.9024165634483069, 0.06016110422988713, 0.03839010155829403, 0.9469558384379194, 0.05085733370316377, 0.1932578680720223, 0.14240053436885855, 0.05085733370316377, 0.5594306707348015, 0.0022508191912909803, 0.7090080452566588, 0.15530652419907764, 0.06302293735614745, 0.024759011104200784, 0.011254095956454902, 0.036013107060655684, 0.9259625238592396, 0.21337457082561137, 0.6279308798582277, 0.15241040773257955, 0.9924298486803635, 0.9544560796288863, 0.05622392711356695, 0.7309110524763703, 0.1874130903785565, 0.2023775727910293, 0.1032538636688925, 0.1280347909494267, 0.0578221636545798, 0.3675837546612573, 0.1362951000429381, 0.6246771203844923, 0.14992250889227815, 0.09994833926151876, 0.09994833926151876, 0.19210562119213287, 0.7564158834440232, 0.04802640529803322, 0.5106576284567932, 0.039619988414751194, 0.44902653536718024, 0.8783739982595312, 0.07638034767474185, 0.03708230487613389, 0.010594944250323968, 0.052974721251619845, 0.8899753170272134, 0.10219767572828994, 0.8789000112632935, 0.16615433963131582, 0.16615433963131582, 0.6646173585252633, 0.0032410867078835194, 0.4440288789800422, 0.5509847403401983, 0.39081186816403063, 0.6087646407939709, 0.06631954979770605, 0.04144971862356628, 0.27356814291553744, 0.6134558356287809, 0.9878805784808378, 0.9985977409569547], \"Term\": [\"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"account\", \"account\", \"account\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"activate\", \"activate\", \"active\", \"active\", \"active\", \"active\", \"active\", \"activity\", \"activity\", \"activity\", \"activitythread\", \"actors\", \"actors\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"alamofire\", \"alamofire\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"animation\", \"animation\", \"anymore\", \"anymore\", \"anymore\", \"apilint\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"applewebkit\", \"applewebkit\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"applications\", \"applications\", \"approach\", \"article\", \"article\", \"artifacts\", \"artifacts\", \"artifacts\", \"assertionerror\", \"assertthat\", \"associate\", \"associate\", \"attach\", \"attach\", \"attach\", \"attach\", \"attachment\", \"attachment\", \"attachment\", \"attachment\", \"attachment\", \"background\", \"background\", \"background\", \"background\", \"background\", \"backtrace\", \"backtrace\", \"basesessiontest\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"better\", \"blobber\", \"bookmark\", \"bookmark\", \"bookmarks\", \"branch\", \"branch\", \"branch\", \"branch\", \"briefly\", \"browse\", \"browse\", \"browse\", \"browse\", \"browse\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"browser\", \"buffer\", \"bugzilla\", \"bugzilla\", \"bugzilla\", \"bundle\", \"bundle\", \"bundle\", \"bundle\", \"button\", \"button\", \"button\", \"button\", \"button\", \"camera\", \"camera\", \"cancel\", \"capture\", \"capture\", \"capture\", \"carthage\", \"carthage\", \"central\", \"central\", \"central\", \"central\", \"cfrunlooprun\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"channel\", \"character\", \"character\", \"character\", \"checkthat\", \"chrome\", \"chrome\", \"chrome\", \"chrome\", \"chrome\", \"chrome\", \"chrome\", \"cleanup\", \"client\", \"client\", \"client\", \"client\", \"client\", \"clients\", \"closure\", \"closure\", \"collection\", \"command\", \"command\", \"command\", \"commit\", \"commit\", \"commit\", \"commit\", \"common\", \"common\", \"compilation\", \"compilation\", \"compile\", \"compile\", \"components\", \"components\", \"compositor\", \"compositor\", \"compositor\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"confirm\", \"confirm\", \"confirm\", \"confuse\", \"confuse\", \"connect\", \"connect\", \"connect\", \"connection\", \"connection\", \"connection\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"continue\", \"continue\", \"continue\", \"convert\", \"cookies\", \"cookies\", \"corefoundation\", \"corner\", \"corner\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correctly\", \"correctly\", \"correctly\", \"correctly\", \"correctly\", \"correctly\", \"counter\", \"couple\", \"couple\", \"couple\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"currently\", \"cursor\", \"cursor\", \"custom\", \"custom\", \"dalvik\", \"dalvik\", \"database\", \"debugger\", \"decide\", \"decide\", \"decide\", \"decide\", \"default\", \"default\", \"default\", \"default\", \"default\", \"default\", \"default\", \"delegate\", \"delete\", \"delete\", \"delete\", \"delete\", \"dependencies\", \"dependencies\", \"dependency\", \"dependent\", \"dependent\", \"deprecate\", \"description\", \"description\", \"description\", \"description\", \"desktop\", \"desktop\", \"desktop\", \"desktop\", \"determine\", \"determine\", \"developer\", \"developer\", \"development\", \"development\", \"device\", \"device\", \"device\", \"device\", \"device\", \"devices\", \"devices\", \"devices\", \"devices\", \"devices\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"directly\", \"directly\", \"directly\", \"directory\", \"directory\", \"directory\", \"disable\", \"disable\", \"disable\", \"disable\", \"disable\", \"disappear\", \"discussion\", \"dispatch\", \"dispatch\", \"dispatch\", \"dispatchmessage\", \"dispatchmessage\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"download\", \"download\", \"download\", \"download\", \"download\", \"download\", \"dynamic\", \"dynamic\", \"easily\", \"easily\", \"easily\", \"element\", \"element\", \"element\", \"element\", \"element\", \"elements\", \"elements\", \"elements\", \"enable\", \"enable\", \"enable\", \"enable\", \"enable\", \"enable\", \"enable\", \"engine\", \"engine\", \"ensure\", \"ensure\", \"enterprise\", \"enterprise\", \"enterprise\", \"errorcollector\", \"evaluate\", \"events\", \"events\", \"events\", \"exactly\", \"exactly\", \"exactly\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"examples\", \"exception\", \"exception\", \"exception\", \"expand\", \"expect\", \"expect\", \"expect\", \"expect\", \"expect\", \"expect\", \"experience\", \"experience\", \"extension\", \"extension\", \"extension\", \"extensions\", \"external\", \"external\", \"external\", \"failures\", \"failures\", \"failures\", \"family\", \"fastmult\", \"favicon\", \"favicon\", \"favicon\", \"favicons\", \"favicons\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feedback\", \"feedback\", \"fennec\", \"fennec\", \"fennec\", \"fennec\", \"fennec\", \"fennec\", \"fennec\", \"filename\", \"filename\", \"filter\", \"filter\", \"finger\", \"finger\", \"finger\", \"firefox\", \"firefox\", \"firefox\", \"firefox\", \"firefox\", \"firefox\", \"firefox\", \"fission\", \"fission\", \"folder\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forward\", \"forward\", \"forward\", \"framework\", \"framework\", \"framework\", \"frameworkmethod\", \"fullscreen\", \"fullscreen\", \"fxscreengraph\", \"galaxy\", \"galaxy\", \"geckoappshell\", \"geckoappshell\", \"geckoloader\", \"geckoruntime\", \"geckosession\", \"geckosession\", \"geckosession\", \"geckosession\", \"geckosession\", \"geckothread\", \"geckothread\", \"geckothread\", \"geckoview\", \"geckoview\", \"geckoview\", \"geckoview\", \"geckoview\", \"geckoviewmodule\", \"generate\", \"generate\", \"github\", \"github\", \"github\", \"github\", \"google\", \"google\", \"google\", \"gradle\", \"gradle\", \"gseventrunmodal\", \"hamburger\", \"hamcrest\", \"handle\", \"handle\", \"handle\", \"handlecallback\", \"handleevent\", \"handleevent\", \"handleevent\", \"handlemessage\", \"handler\", \"handler\", \"handler\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"header\", \"highlight\", \"highlight\", \"highlight\", \"history\", \"history\", \"history\", \"history\", \"homepage\", \"identify\", \"identify\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"incorrect\", \"incorrect\", \"information\", \"information\", \"information\", \"information\", \"information\", \"initially\", \"initially\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instruction\", \"instrumentation\", \"instrumentation\", \"integration\", \"integration\", \"intent\", \"intent\", \"intermittent\", \"intermittent\", \"intermittent\", \"intermittently\", \"intermittently\", \"intermittently\", \"internal\", \"internal\", \"internet\", \"investigate\", \"investigate\", \"investigate\", \"invoke\", \"invoke\", \"invoke\", \"invoke\", \"invokemethod\", \"invokenative\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"javadoc\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"lambda\", \"lambda\", \"landscape\", \"latest\", \"latest\", \"latest\", \"latest\", \"launch\", \"launch\", \"launch\", \"leanplum\", \"leanplum\", \"leanplum\", \"leanplum\", \"leanplum\", \"libart\", \"libdispatch\", \"libdyld\", \"libmozglue\", \"libraries\", \"libraries\", \"library\", \"library\", \"library\", \"libxul\", \"linearalloc\", \"listener\", \"listener\", \"listener\", \"locale\", \"locales\", \"locales\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"logins\", \"logins\", \"looper\", \"management\", \"management\", \"manifest\", \"manifest\", \"maperr\", \"master\", \"master\", \"master\", \"master\", \"master\", \"matcherassert\", \"measure\", \"measure\", \"memory\", \"memory\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"messageloop\", \"messagepump\", \"metadata\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"migrate\", \"migrate\", \"migration\", \"migration\", \"migration\", \"migration\", \"minidump\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mochitest\", \"mochitest\", \"modify\", \"modify\", \"modify\", \"modify\", \"modify\", \"module\", \"module\", \"module\", \"modules\", \"modules\", \"modules\", \"modules\", \"modules\", \"mozafterpaint\", \"mozcrash\", \"mozharness\", \"mozilla\", \"mozilla\", \"mozilla\", \"mozilla\", \"mozilla\", \"mozilla\", \"mozilla\", \"mozilla\", \"nativerun\", \"natives\", \"notice\", \"notice\", \"notice\", \"notice\", \"notice\", \"notification\", \"notification\", \"notification\", \"notifications\", \"notifications\", \"notifications\", \"notify\", \"notify\", \"notify\", \"notify\", \"nsthread\", \"nsthreadutils\", \"number\", \"number\", \"number\", \"number\", \"numtests\", \"numtests\", \"onboarding\", \"onboarding\", \"onevent\", \"operate\", \"operate\", \"operate\", \"option\", \"option\", \"option\", \"option\", \"option\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"orientation\", \"orientation\", \"origin\", \"origin\", \"originally\", \"output\", \"output\", \"output\", \"output\", \"output\", \"overlap\", \"package\", \"pageshow\", \"parameter\", \"parameter\", \"partial\", \"password\", \"password\", \"passwords\", \"people\", \"people\", \"people\", \"people\", \"persist\", \"pocket\", \"pocket\", \"pocket\", \"pointer\", \"policy\", \"policy\", \"policy\", \"portrait\", \"portrait\", \"position\", \"position\", \"position\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"preempt\", \"preview\", \"preview\", \"previous\", \"previous\", \"privacy\", \"privacy\", \"private\", \"private\", \"private\", \"private\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"produce\", \"produce\", \"production\", \"production\", \"profile\", \"profile\", \"profile\", \"profile\", \"profile\", \"progresstracker\", \"project\", \"project\", \"prompt\", \"prompt\", \"proper\", \"proper\", \"property\", \"property\", \"protection\", \"protection\", \"protection\", \"protection\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"public\", \"public\", \"python\", \"python\", \"reader\", \"reality\", \"reality\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"recently\", \"recently\", \"record\", \"record\", \"reddit\", \"reddit\", \"redirect\", \"redirect\", \"reflect\", \"regress\", \"regress\", \"regular\", \"regular\", \"regular\", \"regular\", \"relate\", \"relate\", \"relate\", \"relate\", \"relate\", \"release\", \"release\", \"release\", \"release\", \"release\", \"release\", \"release\", \"release\", \"reload\", \"reload\", \"reload\", \"reload\", \"remote\", \"remote\", \"remove\", \"remove\", \"remove\", \"remove\", \"remove\", \"remove\", \"remove\", \"remove\", \"remove\", \"render\", \"render\", \"render\", \"report\", \"report\", \"report\", \"report\", \"reporter\", \"reporter\", \"reproduce\", \"reproduce\", \"reproduce\", \"reproduce\", \"reproduce\", \"reproducible\", \"reproducible\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"requisites\", \"resolve\", \"resolve\", \"resolve\", \"resource\", \"resource\", \"resource\", \"restore\", \"restore\", \"restore\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"return\", \"return\", \"return\", \"return\", \"return\", \"return\", \"review\", \"review\", \"revision\", \"revision\", \"runners\", \"safari\", \"safari\", \"sample\", \"sample\", \"samsung\", \"samsung\", \"scenario\", \"scenario\", \"scenarios\", \"scenarios\", \"scenarios\", \"schema\", \"schema\", \"scheme\", \"scheme\", \"scheme\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screenshot\", \"screenshots\", \"screenshots\", \"script\", \"script\", \"script\", \"script\", \"scroll\", \"scroll\", \"scroll\", \"scroll\", \"scroll\", \"scroll\", \"search\", \"search\", \"search\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"section\", \"section\", \"section\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"sentry\", \"sentry\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"session\", \"session\", \"session\", \"session\", \"session\", \"sessions\", \"settings\", \"settings\", \"settings\", \"settings\", \"settings\", \"settings\", \"shortmsg\", \"shouldn\", \"shouldn\", \"sigabrt\", \"sigsegv\", \"simulator\", \"simulator\", \"simulator\", \"smaller\", \"smaller\", \"smoketest\", \"smoketest\", \"socorro\", \"socorro\", \"solution\", \"solution\", \"solution\", \"solution\", \"source\", \"source\", \"source\", \"special\", \"special\", \"sqlite\", \"sqlite\", \"ssltunnel\", \"stackwalk\", \"statements\", \"static\", \"static\", \"static\", \"static\", \"status\", \"status\", \"status\", \"storage\", \"storage\", \"stories\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"string\", \"string\", \"string\", \"string\", \"string\", \"success\", \"success\", \"suggestion\", \"suggestion\", \"suggestions\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"surface\", \"surface\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switcher\", \"switcher\", \"symbol\", \"symbols\", \"syncrunnable\", \"tabmanager\", \"taskcluster\", \"things\", \"things\", \"things\", \"things\", \"things\", \"thread\", \"thread\", \"thread\", \"thread\", \"timeoutrunnable\", \"tinderboxprint\", \"toggle\", \"toggle\", \"toolbar\", \"toolbar\", \"toolkit\", \"topsites\", \"twitter\", \"twitter\", \"twitter\", \"uitests\", \"uithreadutils\", \"unable\", \"unable\", \"unable\", \"unable\", \"unexpected\", \"unexpected\", \"unexpected\", \"unexpected\", \"unexpected\", \"unknown\", \"unknown\", \"unknown\", \"unresponsive\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"upgrade\", \"upgrade\", \"upload\", \"upload\", \"upload\", \"uptime\", \"urlbar\", \"username\", \"usually\", \"usually\", \"variant\", \"variant\", \"verify\", \"verify\", \"verify\", \"verify\", \"verify\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"viewport\", \"visible\", \"visible\", \"visible\", \"waituntilcalled\", \"webextensions\", \"webkit\", \"webkit\", \"webkit\", \"website\", \"website\", \"website\", \"website\", \"website\", \"website\", \"websites\", \"websites\", \"websites\", \"websites\", \"webview\", \"webview\", \"webview\", \"widget\", \"widget\", \"widget\", \"wikipedia\", \"wikipedia\", \"window\", \"window\", \"window\", \"window\", \"windows\", \"windows\", \"wonder\", \"wonder\", \"wonder\", \"worker\", \"worker\", \"worker\", \"workspace\", \"workspace\", \"xcuitests\", \"xcuitests\", \"xcuitests\", \"xcuitests\", \"youtube\", \"zygoteinit\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 7, 1, 5, 9, 4, 8, 10, 2, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1311404174355892001834931104\", ldavis_el1311404174355892001834931104_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1311404174355892001834931104\", ldavis_el1311404174355892001834931104_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1311404174355892001834931104\", ldavis_el1311404174355892001834931104_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating 10 empty clusters and pushing master reports in each of them based on topic modeling and saving them in individual csv file\n",
        "for c in range(10):\n",
        "    exec('topic_{} = pd.DataFrame()'.format(c))\n",
        "    for i in range(len(master_reports)):\n",
        "        topic=lda_model[dictionary.doc2bow(master_reports.Description[i])]\n",
        "        topic= np.asarray(topic)\n",
        "        if int(topic[np.argmax(topic[:,1]),0])== c:\n",
        "            exec('topic_{} = topic_{}.append(master_reports.loc[[i]])'.format(c,c))\n",
        "            exec('topic_{} = topic_{}.reset_index(drop=True)'.format(c,c))\n",
        "            exec('topic_{}.to_csv(\"topic_{}.csv\")'.format(c,c))"
      ],
      "metadata": {
        "id": "CrsYFPvuNPYK"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Open Pickle File\n",
        "file_bow = open('mobile_bow_corpus.pickle', 'rb')\n",
        "bow_corpus = pickle.load(file_bow)\n",
        "\n",
        "file_dict = open('mobile_dictionary.pickle', 'rb')\n",
        "dictionary=pickle.load(file_dict)\n",
        "\n",
        "#To load Trained Model\n",
        "lda_model =  models.LdaModel.load('mobile_lda_model.model')"
      ],
      "metadata": {
        "id": "FGrOGYa3NSJO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Create corpus for Word2Vec and FastText models\n",
        "for i in range(10):\n",
        "    exec('sent_{} = []'.format(i))\n",
        "    exec('x= topic_{}'.format(i))\n",
        "    for j in range(len(x)):\n",
        "        exec('sent_{}.append(topic_{}.Description[{}])'.format(i,i,j))\n",
        "\n",
        "for sent in range(10):\n",
        "    exec('print(len(sent_{}))'.format(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T64bkIl1OIWq",
        "outputId": "7ed0a549-fa4e-4dc3-cfae-3daea69331f6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "618\n",
            "345\n",
            "466\n",
            "532\n",
            "137\n",
            "395\n",
            "733\n",
            "673\n",
            "622\n",
            "243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training GloVe model for each cluster\n",
        "for cluster in range(10):\n",
        "    vector_size = 100\n",
        "    exec('glove_corpus{}=Corpus()'.format(cluster, cluster)) \n",
        "    exec('glove_corpus{}.fit(sent_{})'.format(cluster, cluster))\n",
        "    exec('glove{}= Glove(no_components=vector_size, learning_rate=0.18, alpha=0.75, max_count=100, max_loss=10.0, random_state=None)'.format(cluster, cluster))\n",
        "    exec('glove{}.fit(glove_corpus{}.matrix, epochs=200, no_threads=3, verbose=True)'.format(cluster, cluster))\n",
        "    exec('transformer = lambda dictionary2:glove{}.transform_paragraph(words, epochs=1000,ignore_missing=False)'.format(cluster, cluster))\n",
        "    exec('glove{}.add_dictionary(glove_corpus{}.dictionary)'.format(cluster, cluster))\n",
        "\n",
        "    #Save the all the models in individual file\n",
        "    exec('path = get_tmpfile(\"glove{}.model\")'.format(cluster))\n",
        "    exec('glove{}.save(\"glove{}.model\")'.format(cluster, cluster))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy7TvWMLNv_w",
        "outputId": "35853da3-1637-4f9c-fa25-681fe7d86114"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Performing 200 training epochs with 3 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "edCLRlO7O2RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To Import all the Clusters created using LDA based Topic Modeling\n",
        "for c in range(10):\n",
        "    exec('topic_{} = pd.read_csv(\"topic_{}.csv\")'.format(c,c))\n",
        "    exec(\"topic_{}= topic_{}.drop(columns=['Unnamed: 0'])\".format(c,c))\n",
        "    exec(\"topic_{}['Description'] = topic_{}['Description'].map(preprocess)\".format(c,c))"
      ],
      "metadata": {
        "id": "DxOIGsj5NyIz"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Import all the trained GloVe models\n",
        "for mod in range(10):  \n",
        "    exec('glove{} = Glove.load(\"glove{}.model\")'.format(mod, mod))"
      ],
      "metadata": {
        "id": "nJF0u5RpPg_i"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will return the index of cluster in which the master report of duplicate report may reside\n",
        "def sim_with_clusters_lda_topn(DR, n):\n",
        "    vec_bow = dictionary.doc2bow(DR)\n",
        "    x= lda_model[vec_bow]\n",
        "    topic = np.asarray(x)\n",
        "    sim=[]\n",
        "    x= topic[np.argsort(topic[:,1])[-n:][::-1],0]\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        sim.append(int(x[i]))\n",
        "\n",
        "    return sim\n",
        "\n",
        "#To get Similarity between two feature vectors using the average of Cosine Similarity & Euclidean Similarity\n",
        "def sim(vec1, vec2): \n",
        "    sim1 = 1/(1+np.linalg.norm(np.array(vec1) - np.array(vec2)))\n",
        "    sim2 = cosine_similarity(vec1, vec2)\n",
        "    sim=(sim1+sim2)/2 \n",
        "    return sim"
      ],
      "metadata": {
        "id": "YdwkOSEvPlPx"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LDA and GLOVE**"
      ],
      "metadata": {
        "id": "EpnKk2gLPzfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns Top-N Master Reports\n",
        "def compare_topn(model, cluster, sent, DR, topn, modal):\n",
        "    similarity=[]\n",
        "    \n",
        "    if (modal == 'single'):\n",
        "        vec_duplicate, master= feature_vectors_single_modality(DR, sent, model)\n",
        "    else:\n",
        "        raise ValueError('Invalid Modality entered')\n",
        "\n",
        "    for doc in range(len(master)):\n",
        "        vec_master = master[doc]\n",
        "        vec_master= [vec_master]\n",
        "        unified_sim = sim(vec_duplicate, vec_master)\n",
        "        similarity.append(unified_sim)\n",
        "    \n",
        "    similarity = np.asarray(similarity)\n",
        "    similarity= np.concatenate(similarity, axis=0 )\n",
        "    similarity= np.concatenate(similarity, axis=0 )\n",
        "    max_similar_reports=similarity.argsort()[-topn:][::-1]\n",
        "\n",
        "    return(max_similar_reports)"
      ],
      "metadata": {
        "id": "w8TPjFd_PyTI"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of feature vectors by singlemodality feature extraction\n",
        "def feature_vectors_single_modality(DR, corpus, model):\n",
        "    master = averaged_word_vectorizer_glove(corpus=sent, model=model, num_features=100)\n",
        "\n",
        "    vec_duplicate = averaged_word_vectorizer_glove(corpus=DR, model=model, num_features=100)\n",
        "\n",
        "    vec_duplicate = [vec_duplicate]\n",
        "\n",
        "    return vec_duplicate, master\n",
        "\n",
        "def averaged_word_vectorizer_glove(corpus, model, num_features):\n",
        "    vocabulary = set(model.dictionary)\n",
        "    if(any(isinstance(i, list) for i in corpus)):\n",
        "        features = [average_word_vectors_glove(tokenized_sentence, model, vocabulary, num_features)\n",
        "                      for tokenized_sentence in corpus]\n",
        "        return np.array(features)\n",
        "    else:\n",
        "          features = average_word_vectors_glove(corpus, model, vocabulary, num_features)\n",
        "    return np.array(features)\n",
        "\n",
        "def average_word_vectors_glove(words, model, vocabulary, num_features):  \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    nwords = 0.  \n",
        "\n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vector = np.add(feature_vector, model.word_vectors[model.dictionary[word]])\n",
        "\n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "        \n",
        "    return feature_vector"
      ],
      "metadata": {
        "id": "olzYGJuCP3R7"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data\n",
        "\n",
        "Determining the top-n values for the recall rate @ k"
      ],
      "metadata": {
        "id": "RqfoaGo6P8dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Duplicate Reports\n",
        "test = pd.read_csv('mobile_duplicate_reports.csv')\n",
        "test = test.drop(columns=['Unnamed: 0'])\n",
        "test['Description']= test['Description'].fillna('').astype(str).map(preprocess)\n",
        "test = test.rename(columns={'Bug ID':'Bug_ID'})\n",
        "\n",
        "#To Decide the Iterations\n",
        "number_of_samples = test.shape[0]\n",
        "\n",
        "if(number_of_samples > 200):\n",
        "  number_of_samples = 200"
      ],
      "metadata": {
        "id": "tyQCJE6kZnaq"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the performance by Recall Rate\n",
        "def evaluate(vec_acc, t2, t1):\n",
        "  sum = 0\n",
        "  for i,num in enumerate(vec_acc):\n",
        "      sum = sum + int(num)\n",
        "  recall_rate = (sum/len(vec_acc))*100\n",
        "  print(\"Recall Rate : {} %\".format(recall_rate))\n",
        "  print(\"Time : \", (t2-t1)/60, \"min\")"
      ],
      "metadata": {
        "id": "XOntmWZcoQpi"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=1\n",
        "vec_acc_top1=[]\n",
        "t1_top1 = time.time()\n",
        "\n",
        "for i in range(number_of_samples):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test.Description[i] \n",
        "    n = 1\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max)) \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))\n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1  \n",
        "        modal = 'single'                                 \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top1 = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top1.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top1.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU-r0jXhfFOP",
        "outputId": "be904351-fa19-4e2f-ac13-df82df07eb31"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 199"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=5\n",
        "vec_acc_top5=[]\n",
        "t1_top5 = time.time()\n",
        "\n",
        "for i in range(number_of_samples):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max)) \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))\n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1 \n",
        "        modal = 'single'                                 \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top5 = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top5.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top5.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGzhXLZpn69",
        "outputId": "44bdc97c-aa52-43c5-ae37-8f72ff37c1cb"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 199"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=10\n",
        "vec_acc_top10=[]\n",
        "t1_top10 = time.time()\n",
        "\n",
        "for i in range(number_of_samples):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max)) \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))\n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 3  \n",
        "        modal = 'single'                                 \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top10 = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top10.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top10.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ID20CTp3LX",
        "outputId": "50ef0430-2daf-4678-8bea-79438130a12c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 199"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=100\n",
        "vec_acc_top100=[]\n",
        "t1_top100 = time.time()\n",
        "\n",
        "for i in range(number_of_samples):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max)) \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))\n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 33   \n",
        "        modal = 'single'                                 \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top100 = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top100.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top100.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4wxJ7pqC3N",
        "outputId": "2870109f-bf3c-4e91-e40e-b94593929140"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 199"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For k=1')\n",
        "evaluate(vec_acc_top1, t2_top1, t1_top1)\n",
        "\n",
        "print('\\nFor k=5')\n",
        "evaluate(vec_acc_top5, t2_top5, t1_top5)\n",
        "\n",
        "print('\\nFor k=10')\n",
        "evaluate(vec_acc_top10, t2_top10, t1_top10)\n",
        "\n",
        "print('\\nFor k=100')\n",
        "evaluate(vec_acc_top100, t2_top100, t1_top100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFL6LJLNjRcj",
        "outputId": "07330acc-3667-4699-ac38-86e4f574d4ca"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k=1\n",
            "Recall Rate : 0.0 %\n",
            "Time :  0.9672367294629415 min\n",
            "\n",
            "For k=5\n",
            "Recall Rate : 2.5 %\n",
            "Time :  2.6086865504582724 min\n",
            "\n",
            "For k=10\n",
            "Recall Rate : 10.0 %\n",
            "Time :  2.554018723964691 min\n",
            "\n",
            "For k=100\n",
            "Recall Rate : 18.0 %\n",
            "Time :  2.491474755605062 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Textually Similar and Dissimilar Data**"
      ],
      "metadata": {
        "id": "_Ym0NvAJszlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Textually Similar"
      ],
      "metadata": {
        "id": "AeHfgskBr4eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Textually Similar Data\n",
        "test_sim = pd.read_csv('/content/drive/Shareddrives/DSCI-644-Team-5/PreProcessedData/Mobile_final_sim.csv')\n",
        "\n",
        "#Cleaning the Data\n",
        "test_sim = test_sim.drop(columns=['Unnamed: 0'])\n",
        "test_sim['Description']= test_sim['Description'].fillna('').astype(str).map(preprocess)\n",
        "test_sim.replace(\"\", np.nan, inplace=True)\n",
        "test_sim.dropna(subset = [\"Duplicate_Bug_Ids\"], inplace=True)\n",
        "test_sim = test_sim.reset_index(drop=True)\n",
        "\n",
        "#To Decide the Iterations\n",
        "number_of_samples_sim = test_sim.shape[0]\n",
        "\n",
        "if(number_of_samples_sim > 200):\n",
        "  number_of_samples_sim = 200"
      ],
      "metadata": {
        "id": "-D58P1BsPG2M"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=1\n",
        "vec_acc_top1_sim=[]\n",
        "t1_top1_sim = time.time()\n",
        "\n",
        "for i in range(number_of_samples_sim):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_sim.Description[i] \n",
        "    n = 1\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max)) \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))\n",
        "      \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1   \n",
        "        modal = 'single'                                 \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top1_sim = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top1_sim.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top1_sim.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RDaBg1tglW4",
        "outputId": "896904a1-e56d-4a35-c273-8704c6f8fe82"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 121"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=5\n",
        "vec_acc_top5_sim=[]\n",
        "t1_top5_sim = time.time()\n",
        "\n",
        "for i in range(number_of_samples_sim):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_sim.Description[i]\n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))             \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))     \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1           \n",
        "        modal = 'single'        \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top5_sim = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top5_sim.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top5_sim.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r32ErU6uwPtO",
        "outputId": "d5d6741d-6f08-4ec3-9b5c-5fdff0f5a11b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 121"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=10\n",
        "vec_acc_top10_sim=[]\n",
        "t1_top10_sim = time.time()\n",
        "\n",
        "for i in range(number_of_samples_sim):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_sim.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))              \n",
        "        exec('model = glove{}'.format(max))               \n",
        "        exec('sent = topic_{}.Description'.format(max))    \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 3          \n",
        "        modal = 'single'                                    \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top10_sim = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top10_sim.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top10_sim.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgKgKY_cwsn7",
        "outputId": "8e16a2ae-d5c1-4f8f-c9af-d8df798e31b9"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 121"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=100\n",
        "vec_acc_top100_sim=[]\n",
        "t1_top100_sim = time.time()\n",
        "\n",
        "for i in range(number_of_samples_sim):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_sim.Description[i]\n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))              \n",
        "        exec('model = glove{}'.format(max))               \n",
        "        exec('sent = topic_{}.Description'.format(max))     \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 33          \n",
        "        modal = 'single'    \n",
        "\n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top100_sim = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top100_sim.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top100_sim.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GheBGogUxA0O",
        "outputId": "6f05c858-e222-4e2c-e2ae-df58cea388ee"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 121"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For k=1')\n",
        "evaluate(vec_acc_top1_sim, t2_top1_sim, t1_top1_sim)\n",
        "\n",
        "print('\\nFor k=5')\n",
        "evaluate(vec_acc_top5_sim, t2_top5_sim, t1_top5_sim)\n",
        "\n",
        "print('\\nFor k=10')\n",
        "evaluate(vec_acc_top10_sim, t2_top10_sim, t1_top10_sim)\n",
        "\n",
        "print('\\nFor k=100')\n",
        "evaluate(vec_acc_top100_sim, t2_top100_sim, t1_top100_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Wsh8cYu7QE",
        "outputId": "d7a1fcc3-326e-4c69-910e-0cb5af87984f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k=1\n",
            "Recall Rate : 0.0 %\n",
            "Time :  0.5513003865877787 min\n",
            "\n",
            "For k=5\n",
            "Recall Rate : 2.459016393442623 %\n",
            "Time :  1.0479019204775493 min\n",
            "\n",
            "For k=10\n",
            "Recall Rate : 13.114754098360656 %\n",
            "Time :  0.9820038596789042 min\n",
            "\n",
            "For k=100\n",
            "Recall Rate : 22.950819672131146 %\n",
            "Time :  1.163325806458791 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Textually Dissimilar"
      ],
      "metadata": {
        "id": "3yYy3RIVPdH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Textually Similar Data\n",
        "test_dissim = pd.read_csv('/content/drive/Shareddrives/DSCI-644-Team-5/PreProcessedData/Mobile_final_dis.csv')\n",
        "\n",
        "#Cleaning the Data\n",
        "test_dissim = test_dissim.drop(columns=['Unnamed: 0'])\n",
        "test_dissim['Description']= test_dissim['Description'].fillna('').astype(str).map(preprocess)\n",
        "test_dissim.replace(\"\", np.nan, inplace=True)\n",
        "test_dissim.dropna(subset = [\"Duplicate_Bug_Ids\"], inplace=True)\n",
        "test_dissim = test_dissim.reset_index(drop=True)\n",
        "\n",
        "#To Decide the Iterations\n",
        "number_of_samples_dis = test_dissim.shape[0]\n",
        "\n",
        "if(number_of_samples_dis > 200):\n",
        "  number_of_samples_dis = 200"
      ],
      "metadata": {
        "id": "0XwLRct5PdzU"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=1\n",
        "vec_acc_top1_dis=[]\n",
        "t1_top1_dis = time.time()\n",
        "\n",
        "for i in range(number_of_samples_dis):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_dissim.Description[i] \n",
        "    n = 1\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "    \n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))              \n",
        "        exec('model = glove{}'.format(max))               \n",
        "        exec('sent = topic_{}.Description'.format(max))     \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1              \n",
        "        modal = 'single'                                    \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top1_dis = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top1_dis.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top1_dis.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isHWj_qI25_d",
        "outputId": "81eef56d-a339-4d64-8cea-e4e8d5fefee7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 130"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=5\n",
        "vec_acc_top5_dis=[]\n",
        "t1_top5_dis = time.time()\n",
        "\n",
        "for i in range(number_of_samples_dis):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_dissim.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))                       \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))     \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 1          \n",
        "        modal = 'single'                                    \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top5_dis = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top5_dis.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top5_dis.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aChnGZGa4y4T",
        "outputId": "a5b8f46b-ed3c-47f6-89a5-5ec940b6d5a8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 130"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=10\n",
        "vec_acc_top10_dis=[]\n",
        "t1_top10_dis = time.time()\n",
        "\n",
        "for i in range(number_of_samples_dis):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_dissim.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))                         \n",
        "        exec('model = glove{}'.format(max))                \n",
        "        exec('sent = topic_{}.Description'.format(max))     \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 3      \n",
        "        modal = 'single'                                  \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top10_dis = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top10_dis.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top10_dis.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqbDuoBy5xF-",
        "outputId": "f0f8f752-baf9-4c07-a297-4fa252d453df"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 130"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For k=100\n",
        "vec_acc_top100_dis=[]\n",
        "t1_top100_dis = time.time()\n",
        "\n",
        "for i in range(number_of_samples_dis):\n",
        "    print(f'\\rRunning sample {i}', end='')\n",
        "    sample = test_dissim.Description[i] \n",
        "    n = 3\n",
        "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
        "    v=[]\n",
        "\n",
        "    for max in max_cluster:\n",
        "        exec('cluster = topic_{}'.format(max))                \n",
        "        exec('model = glove{}'.format(max))               \n",
        "        exec('sent = topic_{}.Description'.format(max))    \n",
        "        \n",
        "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
        "        topn = 33         \n",
        "        modal = 'single'                                   \n",
        "        \n",
        "        #This will return the Top-N predicted master reports\n",
        "        max_sim = compare_topn(model, cluster, sent, sample, topn, modal)\n",
        "        t2_top100_dis = time.time()\n",
        "\n",
        "        #Comparing the predicted value to the ground truth\n",
        "        for num in max_sim:\n",
        "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
        "                v.append(\"1\")\n",
        "            else:\n",
        "                v.append(\"0\")\n",
        "\n",
        "    if(all(x==v[0] for x in v)):\n",
        "        vec_acc_top100_dis.append(\"0\")\n",
        "    else:\n",
        "        vec_acc_top100_dis.append(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi-tC3Nd6y0g",
        "outputId": "e2b550d7-dca8-4153-c78f-e57c19719b2d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sample 130"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For k=1')\n",
        "evaluate(vec_acc_top1_dis, t2_top1_dis, t1_top1_dis)\n",
        "\n",
        "print('\\nFor k=5')\n",
        "evaluate(vec_acc_top5_dis, t2_top5_dis, t1_top5_dis)\n",
        "\n",
        "print('\\nFor k=10')\n",
        "evaluate(vec_acc_top10_dis, t2_top10_dis, t1_top10_dis)\n",
        "\n",
        "print('\\nFor k=100')\n",
        "evaluate(vec_acc_top100_dis, t2_top100_dis, t1_top100_dis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPdfuaKm4r1M",
        "outputId": "92326f79-c2e3-47cc-f83d-bff7afe33024"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k=1\n",
            "Recall Rate : 0.0 %\n",
            "Time :  0.6100683053334554 min\n",
            "\n",
            "For k=5\n",
            "Recall Rate : 4.580152671755725 %\n",
            "Time :  1.7570760011672975 min\n",
            "\n",
            "For k=10\n",
            "Recall Rate : 6.106870229007633 %\n",
            "Time :  1.7614442745844523 min\n",
            "\n",
            "For k=100\n",
            "Recall Rate : 13.740458015267176 %\n",
            "Time :  1.8518136620521546 min\n"
          ]
        }
      ]
    }
  ]
}