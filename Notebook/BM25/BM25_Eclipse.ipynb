{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5fb99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x11004a990>: Failed to establish a new connection: [Errno 51] Network is unreachable')': /packages/2a/21/f691fb2613100a62b3fa91e9988c991e9ca5b89ea31c0d3152a3210344f9/rank_bm25-0.2.2-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x11004b010>: Failed to establish a new connection: [Errno 51] Network is unreachable')': /packages/2a/21/f691fb2613100a62b3fa91e9988c991e9ca5b89ea31c0d3152a3210344f9/rank_bm25-0.2.2-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/hemantrattey/opt/anaconda3/envs/dsci644/lib/python3.11/site-packages (from rank_bm25) (1.24.2)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c389ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hemantrattey/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import urllib.request\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62249bf4",
   "metadata": {},
   "source": [
    "# For Complete Data with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0f98a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Dataset:  (46316, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug_Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Duplicate_Bug_Ids</th>\n",
       "      <th>Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518088.0</td>\n",
       "      <td>search widget is not workingsearch widget is n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546444.0</td>\n",
       "      <td>Bugcreated attachment   eclipse   hello world</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_ECLIPSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533893.0</td>\n",
       "      <td>AntCompareCVSDebugDocIDEIncubatorPMCRelengReso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>519449.0</td>\n",
       "      <td>Problem with KEY_NAMEin  product pluginsection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>519450.0</td>\n",
       "      <td>Problem with KEY_NAMEin  renametyperefactoring...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIXED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bug_Id                                        Description  \\\n",
       "0  518088.0  search widget is not workingsearch widget is n...   \n",
       "1  546444.0     Bugcreated attachment   eclipse   hello world    \n",
       "2  533893.0  AntCompareCVSDebugDocIDEIncubatorPMCRelengReso...   \n",
       "3  519449.0  Problem with KEY_NAMEin  product pluginsection...   \n",
       "4  519450.0  Problem with KEY_NAMEin  renametyperefactoring...   \n",
       "\n",
       "   Duplicate_Bug_Ids   Resolution  \n",
       "0                NaN      INVALID  \n",
       "1                NaN  NOT_ECLIPSE  \n",
       "2                NaN      INVALID  \n",
       "3                NaN        FIXED  \n",
       "4                NaN        FIXED  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../PrimaryDataset/eclipse_preproccessed_whole_dataset.csv')\n",
    "\n",
    "print('Dimensions of Dataset: ', dataset.shape)\n",
    "\n",
    "#To Create a Copy\n",
    "data = dataset.copy()\n",
    "\n",
    "#To add 'Summary' and 'Description' in a new Column 'Description1'\n",
    "data['Description1'] = data['Summary']+ data['Description']\n",
    "\n",
    "#To add only required Columns\n",
    "data = data[['Bug ID', 'Description1', 'Duplicate_Bug_Ids', 'Resolution']]\n",
    "\n",
    "#To Rename the Columns\n",
    "data = data.rename(columns = {'Bug ID':'Bug_Id', 'Description1':'Description'})\n",
    "\n",
    "#To show Data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f369aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Tokenize Data\n",
    "sentences = data['Description']\n",
    "tokens = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    cleanedTex=re.sub(r'[^\\w\\s]','',str(sentence)).lower()\n",
    "    words = (word_tokenize(cleanedTex))\n",
    "    tokens.append(words)\n",
    "\n",
    "#BM25\n",
    "bm25 = BM25Okapi(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce683772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Blank Values with 'NaN' Values\n",
    "data.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "#Droping Data which has 'Nan' value for 'Description' Column\n",
    "data.dropna(subset = [\"Description\"], inplace=True)\n",
    "\n",
    "#To Reset the index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data['Description']=data['Description'].values.astype('object')\n",
    "\n",
    "#Filtering data based on 'Duplicate_Bug_Ids' Column to get Duplicate Bugs\n",
    "# data = data[data['Duplicate_Bug_Ids'] > 0]\n",
    "# print('Dimensions of Data with Duplicate Bug Ids: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a65724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuplicates(whole_data, data, tokens, bm25):\n",
    "    count=0\n",
    "    dup_indices_with_bug_id = {}\n",
    "    similarity_scores_before = []\n",
    "    similarity_scores = {}\n",
    "    bugs = whole_data['Bug_Id']\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        bug_id = row['Bug_Id']\n",
    "        dup_bug_id = row['Duplicate_Bug_Ids']\n",
    "    \n",
    "        if dup_bug_id not in bugs.values:\n",
    "            count+=1\n",
    "            continue\n",
    "        \n",
    "        similarity_row = bm25.get_scores(tokens[i])\n",
    "        argsort_similarity = np.argsort(similarity_row)[::-1][1:]\n",
    "        #similarity_scores_before = (np.sort(similarity_row)[::-1][1:])\n",
    "        dup_bug_index = list(bugs[bugs == dup_bug_id].index)[0]\n",
    "        dup_ranking = np.argmax(argsort_similarity == np.int64(dup_bug_index)) \n",
    "        dup_indices_with_bug_id[bug_id] = dup_ranking\n",
    "        \n",
    "    return dup_indices_with_bug_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5118309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(dup_indices_with_bug_id):\n",
    "    counts = {1: 0, 5: 0, 10: 0, 20: 0, 25: 0, 30: 0, 50: 0, 75: 0, 100: 0}\n",
    "\n",
    "    for value in dup_indices_with_bug_id.values():\n",
    "        for key in counts.keys():\n",
    "            if(value < key):\n",
    "                counts[key] += 1\n",
    "\n",
    "    N = len(dup_indices_with_bug_id)\n",
    "    \n",
    "    for key in counts.keys():\n",
    "        recall_rate = counts[key]/N\n",
    "        print('Recall Rate at '+str(key)+': ', recall_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22301fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get Duplicate Indices\n",
    "dup_indices_with_bug_id = getDuplicates(data, data, tokens, bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb4a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Complete Dataset: \n",
      "Recall Rate at 1:  0.007026789635485288\n",
      "Recall Rate at 5:  0.00878348704435661\n",
      "Recall Rate at 10:  0.00966183574879227\n",
      "Recall Rate at 20:  0.010540184453227932\n",
      "Recall Rate at 25:  0.011857707509881422\n",
      "Recall Rate at 30:  0.011857707509881422\n",
      "Recall Rate at 50:  0.013614404918752744\n",
      "Recall Rate at 75:  0.015371102327624066\n",
      "Recall Rate at 100:  0.015371102327624066\n"
     ]
    }
   ],
   "source": [
    "#To Calculate Recall\n",
    "print('For Complete Dataset: ')\n",
    "calculate_recall(dup_indices_with_bug_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120e478",
   "metadata": {},
   "source": [
    "# For Textually Similar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7f59cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Dataset:  (679, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug_Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Duplicate_Bug_Ids</th>\n",
       "      <th>Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526539.0</td>\n",
       "      <td>Executing an \"ant\" build in a non java project...</td>\n",
       "      <td>522581.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>521057.0</td>\n",
       "      <td>Internal compiler error: java.lang.NullPointer...</td>\n",
       "      <td>517951.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>515976.0</td>\n",
       "      <td>NPE during execution of org.eclipse.tycho:tych...</td>\n",
       "      <td>512326.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516277.0</td>\n",
       "      <td>Exception when launching servercreated attachm...</td>\n",
       "      <td>517672.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>515243.0</td>\n",
       "      <td>Oxygen installation via Eclipse Installer curr...</td>\n",
       "      <td>515213.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bug_Id                                        Description  \\\n",
       "0  526539.0  Executing an \"ant\" build in a non java project...   \n",
       "1  521057.0  Internal compiler error: java.lang.NullPointer...   \n",
       "2  515976.0  NPE during execution of org.eclipse.tycho:tych...   \n",
       "3  516277.0  Exception when launching servercreated attachm...   \n",
       "4  515243.0  Oxygen installation via Eclipse Installer curr...   \n",
       "\n",
       "   Duplicate_Bug_Ids Resolution  \n",
       "0           522581.0  DUPLICATE  \n",
       "1           517951.0  DUPLICATE  \n",
       "2           512326.0  DUPLICATE  \n",
       "3           517672.0  DUPLICATE  \n",
       "4           515213.0  DUPLICATE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sim = pd.read_csv('../../PreProcessedData/Eclipse_final_sim.csv')\n",
    "\n",
    "print('Dimensions of Dataset: ', dataset_sim.shape)\n",
    "\n",
    "#To Create a Copy\n",
    "data_sim = dataset_sim.copy()\n",
    "\n",
    "#To add 'Summary' and 'Description' in a new Column 'Description1'\n",
    "data_sim['Description1'] = data_sim['Summary']+ data_sim['Description']\n",
    "\n",
    "#To add only required Columns\n",
    "data_sim = data_sim[['Bug ID', 'Description1', 'Duplicate_Bug_Ids', 'Resolution']]\n",
    "\n",
    "#To Rename the Columns\n",
    "data_sim = data_sim.rename(columns = {'Bug ID':'Bug_Id', 'Description1':'Description'})\n",
    "\n",
    "#To show Data\n",
    "data_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864ab918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Tokenize Data\n",
    "sentences = data_sim['Description']\n",
    "tokens_sim = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    cleanedTex=re.sub(r'[^\\w\\s]','',str(sentence)).lower()\n",
    "    words = (word_tokenize(cleanedTex))\n",
    "    tokens_sim.append(words)\n",
    "\n",
    "#BM25\n",
    "bm25 = BM25Okapi(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5550f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Blank Values with 'NaN' Values\n",
    "data_sim.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "#Droping Data which has 'Nan' value for 'Description' Column\n",
    "data_sim.dropna(subset = [\"Description\"], inplace=True)\n",
    "\n",
    "#To Reset the index\n",
    "data_sim = data_sim.reset_index(drop=True)\n",
    "\n",
    "data_sim['Description']=data_sim['Description'].values.astype('object')\n",
    "\n",
    "#Filtering data based on 'Duplicate_Bug_Ids' Column to get Duplicate Bugs\n",
    "# data_sim = data_sim[data_sim['Duplicate_Bug_Ids'] > 0]\n",
    "# print('Dimensions of Data with Duplicate Bug Ids: ', data_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe76ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get Duplicate Indices\n",
    "dup_indices_with_bug_id_similar = getDuplicates(data, data_sim, tokens_sim, bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91abcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Textually Similar Dataset: \n",
      "Recall Rate at 1:  0.011904761904761904\n",
      "Recall Rate at 5:  0.013888888888888888\n",
      "Recall Rate at 10:  0.015873015873015872\n",
      "Recall Rate at 20:  0.01984126984126984\n",
      "Recall Rate at 25:  0.01984126984126984\n",
      "Recall Rate at 30:  0.01984126984126984\n",
      "Recall Rate at 50:  0.021825396825396824\n",
      "Recall Rate at 75:  0.023809523809523808\n",
      "Recall Rate at 100:  0.023809523809523808\n"
     ]
    }
   ],
   "source": [
    "#To Calculate Recall\n",
    "print('For Textually Similar Dataset: ')\n",
    "calculate_recall(dup_indices_with_bug_id_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a1e38",
   "metadata": {},
   "source": [
    "# For Textually Dissimilar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd244eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Dataset:  (662, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug_Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Duplicate_Bug_Ids</th>\n",
       "      <th>Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576714.0</td>\n",
       "      <td>Upgrade org.apache.sshd:sshd-core to version 2...</td>\n",
       "      <td>574220.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517250.0</td>\n",
       "      <td>[release] Eclipse Oxygen (4.7)we ll use this b...</td>\n",
       "      <td>517249.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538671.0</td>\n",
       "      <td>JIPP for Concurrency Utilities RIplease create...</td>\n",
       "      <td>538670.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>527762.0</td>\n",
       "      <td>Cross site scriptingcreated attachment   eclis...</td>\n",
       "      <td>518274.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539770.0</td>\n",
       "      <td>The \"allow cookies\" notice appears for every s...</td>\n",
       "      <td>552928.0</td>\n",
       "      <td>DUPLICATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bug_Id                                        Description  \\\n",
       "0  576714.0  Upgrade org.apache.sshd:sshd-core to version 2...   \n",
       "1  517250.0  [release] Eclipse Oxygen (4.7)we ll use this b...   \n",
       "2  538671.0  JIPP for Concurrency Utilities RIplease create...   \n",
       "3  527762.0  Cross site scriptingcreated attachment   eclis...   \n",
       "4  539770.0  The \"allow cookies\" notice appears for every s...   \n",
       "\n",
       "   Duplicate_Bug_Ids Resolution  \n",
       "0           574220.0  DUPLICATE  \n",
       "1           517249.0  DUPLICATE  \n",
       "2           538670.0  DUPLICATE  \n",
       "3           518274.0  DUPLICATE  \n",
       "4           552928.0  DUPLICATE  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dissim = pd.read_csv('../../PreProcessedData/Eclipse_final_dis.csv')\n",
    "\n",
    "print('Dimensions of Dataset: ', dataset_dissim.shape)\n",
    "\n",
    "#To Create a Copy\n",
    "data_dissim = dataset_dissim.copy()\n",
    "\n",
    "#To add 'Summary' and 'Description' in a new Column 'Description1'\n",
    "data_dissim['Description1'] = data_dissim['Summary']+ data_dissim['Description']\n",
    "\n",
    "#To add only required Columns\n",
    "data_dissim = data_dissim[['Bug ID', 'Description1', 'Duplicate_Bug_Ids', 'Resolution']]\n",
    "\n",
    "#To Rename the Columns\n",
    "data_dissim = data_dissim.rename(columns = {'Bug ID':'Bug_Id', 'Description1':'Description'})\n",
    "\n",
    "#To show Data\n",
    "data_dissim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876983c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Tokenize Data\n",
    "sentences = data_dissim['Description']\n",
    "tokens_dissim = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    cleanedTex=re.sub(r'[^\\w\\s]','',str(sentence)).lower()\n",
    "    words = (word_tokenize(cleanedTex))\n",
    "    tokens_dissim.append(words)\n",
    "\n",
    "#BM25\n",
    "bm25 = BM25Okapi(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bca6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Blank Values with 'NaN' Values\n",
    "data_dissim.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "#Droping Data which has 'Nan' value for 'Description' Column\n",
    "data_dissim.dropna(subset = [\"Description\"], inplace=True)\n",
    "\n",
    "#To Reset the index\n",
    "data_dissim = data_dissim.reset_index(drop=True)\n",
    "\n",
    "data_dissim['Description']=data_dissim['Description'].values.astype('object')\n",
    "\n",
    "#Filtering data based on 'Duplicate_Bug_Ids' Column to get Duplicate Bugs\n",
    "# data_dissim = data_dissim[data_dissim['Duplicate_Bug_Ids'] > 0]\n",
    "# print('Dimensions of Data with Duplicate Bug Ids: ', data_dissim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779fa7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get Duplicate Indices\n",
    "dup_indices_with_bug_id_dissimilar = getDuplicates(data, data_dissim, tokens_dissim, bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c48d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Textually Dissimilar Dataset: \n",
      "Recall Rate at 1:  0.014084507042253521\n",
      "Recall Rate at 5:  0.01609657947686117\n",
      "Recall Rate at 10:  0.028169014084507043\n",
      "Recall Rate at 20:  0.03219315895372234\n",
      "Recall Rate at 25:  0.03621730382293763\n",
      "Recall Rate at 30:  0.03621730382293763\n",
      "Recall Rate at 50:  0.04627766599597585\n",
      "Recall Rate at 75:  0.05030181086519115\n",
      "Recall Rate at 100:  0.05030181086519115\n"
     ]
    }
   ],
   "source": [
    "#To Calculate Recall\n",
    "print('For Textually Dissimilar Dataset: ')\n",
    "calculate_recall(dup_indices_with_bug_id_dissimilar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci644",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d862dcca3dec25337c6b8ea79a19adb8b89bccef60bc2564ce15831b7131c2ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
